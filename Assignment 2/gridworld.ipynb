{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit ('torch': conda)",
      "metadata": {
        "interpreter": {
          "hash": "d8957633bcb1ab41d2dfd9b11a55d25ae2b194ad0d644559562952e6e1dd74ed"
        }
      }
    },
    "colab": {
      "name": "Copy of IITM_Assignment_2_Gridworld_Release.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-tkKaYpFE7b"
      },
      "source": [
        "# What is the notebook about?\n",
        "\n",
        "## Problem - Gridworld Environment Algorithms\n",
        "This problem deals with a grid world and stochastic actions. The tasks you have to do are:\n",
        "- Implement Policy Iteration\n",
        "- Implement Value Iteration\n",
        "- Implement TD lamdda\n",
        "- Visualize the results\n",
        "- Explain the results\n",
        "\n",
        "## How to use this notebook? 📝\n",
        "\n",
        "- This is a shared template and any edits you make here will not be saved.**You\n",
        "should make a copy in your own drive**. Click the \"File\" menu (top-left), then \"Save a Copy in Drive\". You will be working in your copy however you like.\n",
        "\n",
        "- **Update the config parameters**. You can define the common variables here\n",
        "\n",
        "Variable | Description\n",
        "--- | ---\n",
        "`AICROWD_DATASET_PATH` | Path to the file containing test data. This should be an absolute path.\n",
        "`AICROWD_RESULTS_DIR` | Path to write the output to.\n",
        "`AICROWD_ASSETS_DIR` | In case your notebook needs additional files (like model weights, etc.,), you can add them to a directory and specify the path to the directory here (please specify relative path). The contents of this directory will be sent to AIcrowd for evaluation.\n",
        "`AICROWD_API_KEY` | In order to submit your code to AIcrowd, you need to provide your account's API key. This key is available at https://www.aicrowd.com/participants/me\n",
        "\n",
        "- **Installing packages**. Please use the [Install packages 🗃](#install-packages-) section to install the packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heQxmuKTFPOs"
      },
      "source": [
        "# Setup AIcrowd Utilities 🛠\n",
        "\n",
        "We use this to bundle the files for submission and create a submission on AIcrowd. Do not edit this block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vG34fKrFVdB"
      },
      "source": [
        "!pip install aicrowd-cli > /dev/null "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxjtlHYfFY8D"
      },
      "source": [
        "# AIcrowd Runtime Configuration 🧷\n",
        "\n",
        "Get login API key from https://www.aicrowd.com/participants/me"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHzbjJlgFWVn"
      },
      "source": [
        "import os\n",
        "\n",
        "AICROWD_DATASET_PATH = os.getenv(\"DATASET_PATH\", os.getcwd()+\"/a5562c7d-55f0-4d06-841c-110655bb04ec_a2_gridworld_inputs.zip\")\n",
        "AICROWD_RESULTS_DIR = os.getenv(\"OUTPUTS_DIR\", \"results\")\n",
        "API_KEY = \"a98ef81b017008edad014f38a0bb30ae\" # Get your key from https://www.aicrowd.com/participants/me"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgcZT-NwFgnB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a22b7f-d5ab-439d-8a39-b7f97225e0f3"
      },
      "source": [
        "!aicrowd login --api-key $API_KEY\n",
        "!aicrowd dataset download -c iit-m-rl-assignment-2-gridworld"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mAPI Key valid\u001b[0m\n",
            "\u001b[32mSaved API Key successfully!\u001b[0m\n",
            "a5562c7d-55f0-4d06-841c-110655bb04ec_a2_gridworld_inputs.zip: 100% 14.2k/14.2k [00:00<00:00, 414kB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkeDMhD-FsUY"
      },
      "source": [
        "!unzip -q $AICROWD_DATASET_PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pylvv2LbFxwg"
      },
      "source": [
        "DATASET_DIR = 'inputs/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_R6ORKqF6KL"
      },
      "source": [
        "# GridWorld Environment\n",
        "Read the code for the environment thoroughly\n",
        "\n",
        "Do not edit the code for the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU_B4PONFE7h"
      },
      "source": [
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "\n",
        "class GridEnv_HW2:\n",
        "    def __init__(self, \n",
        "                 goal_location, \n",
        "                 action_stochasticity,\n",
        "                 non_terminal_reward,\n",
        "                 terminal_reward,\n",
        "                 grey_in,\n",
        "                 brown_in,\n",
        "                 grey_out,\n",
        "                 brown_out\n",
        "                ):\n",
        "\n",
        "        # Do not edit this section \n",
        "        self.action_stochasticity = action_stochasticity\n",
        "        self.non_terminal_reward = non_terminal_reward\n",
        "        self.terminal_reward = terminal_reward\n",
        "        self.grid_size = [10, 10]\n",
        "\n",
        "        # Index of the actions \n",
        "        self.actions = {'N': (1, 0), \n",
        "                        'E': (0,1),\n",
        "                        'S': (-1,0), \n",
        "                        'W': (0,-1)}\n",
        "        \n",
        "        self.perpendicular_order = ['N', 'E', 'S', 'W']\n",
        "        \n",
        "        l = ['normal' for _ in range(self.grid_size[0]) ]\n",
        "        self.grid = np.array([l for _ in range(self.grid_size[1]) ], dtype=object)\n",
        "\n",
        "        self.grid[goal_location[0], goal_location[1]] = 'goal'\n",
        "        self.goal_location = goal_location\n",
        "\n",
        "        for gi in grey_in:\n",
        "            self.grid[gi[0],gi[1]] = 'grey_in'\n",
        "        for bi in brown_in:    \n",
        "            self.grid[bi[0], bi[1]] = 'brown_in'\n",
        "\n",
        "        for go in grey_out:    \n",
        "            self.grid[go[0], go[1]] = 'grey_out'\n",
        "        for bo in brown_out:    \n",
        "            self.grid[bo[0], bo[1]] = 'brown_out'\n",
        "\n",
        "        self.grey_outs = grey_out\n",
        "        self.brown_outs = brown_out\n",
        "\n",
        "    def _out_of_grid(self, state):\n",
        "        if state[0] < 0 or state[1] < 0:\n",
        "            return True\n",
        "        elif state[0] > self.grid_size[0] - 1:\n",
        "            return True\n",
        "        elif state[1] > self.grid_size[1] - 1:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def _grid_state(self, state):\n",
        "        return self.grid[state[0], state[1]]        \n",
        "        \n",
        "    def get_transition_probabilites_and_reward(self, state, action):\n",
        "        \"\"\" \n",
        "        Returns the probabiltity of all possible transitions for the given action in the form:\n",
        "        A list of tuples of (next_state, probability, reward)\n",
        "        Note that based on number of state and action there can be many different next states\n",
        "        Unless the state is All the probabilities of next states should add up to 1\n",
        "        \"\"\"\n",
        "\n",
        "        grid_state = self._grid_state(state)\n",
        "        \n",
        "        if grid_state == 'goal':\n",
        "            return [(self.goal_location, 1.0, 0.0)]\n",
        "        elif grid_state == 'grey_in':\n",
        "            npr = []\n",
        "            for go in self.grey_outs:\n",
        "                npr.append((go, 1/len(self.grey_outs), \n",
        "                            self.non_terminal_reward))\n",
        "            return npr\n",
        "        elif grid_state == 'brown_in':\n",
        "            npr = []\n",
        "            for bo in self.brown_outs:\n",
        "                npr.append((bo, 1/len(self.brown_outs), \n",
        "                            self.non_terminal_reward))\n",
        "            return npr\n",
        "        \n",
        "        direction = self.actions.get(action, None)\n",
        "        if direction is None:\n",
        "            raise ValueError(\"Invalid action %s , please select among\" % action, list(self.actions.keys()))\n",
        "\n",
        "        dir_index = self.perpendicular_order.index(action)\n",
        "        wrap_acts = self.perpendicular_order[dir_index:] + self.perpendicular_order[:dir_index]\n",
        "        next_state_probs = {}\n",
        "        for prob, a in zip(self.action_stochasticity, wrap_acts):\n",
        "            d = self.actions[a]\n",
        "            next_state = (state[0] + d[0]), (state[1] + d[1])\n",
        "            if self._out_of_grid(next_state):\n",
        "                next_state = state\n",
        "            next_state_probs.setdefault(next_state, 0.0)\n",
        "            next_state_probs[next_state] += prob\n",
        "\n",
        "        npr = []\n",
        "        for ns, prob in next_state_probs.items():\n",
        "            next_grid_state = self._grid_state(ns)\n",
        "            reward = self.terminal_reward if next_grid_state == 'goal' else self.non_terminal_reward\n",
        "            npr.append((ns, prob, reward))\n",
        "\n",
        "        return npr\n",
        "\n",
        "    def step(self, state, action):\n",
        "        npr = self.get_transition_probabilites_and_reward(state, action)\n",
        "        probs = [t[1] for t in npr]\n",
        "        sampled_idx = np.random.choice(range(len(npr)), p=probs)\n",
        "        sampled_npr = npr[sampled_idx]\n",
        "        next_state = sampled_npr[0]\n",
        "        reward = sampled_npr[2]\n",
        "        is_terminal = next_state == tuple(self.goal_location)\n",
        "        return next_state, reward, is_terminal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sies5zyRF-Hm"
      },
      "source": [
        "## Example environment\n",
        "\n",
        "This has the same setup as the pdf, do not edit the settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dK1VSsxFE7j"
      },
      "source": [
        "def get_base_kwargs():\n",
        "    goal_location = (9,9)\n",
        "    action_stochasticity = [0.8, 0.2/3, 0.2/3, 0.2/3]\n",
        "    grey_out = [(3,2), (4,2), (5,2), (6,2)]\n",
        "    brown_in = [(9,7)]\n",
        "    grey_in = [(0,0)]\n",
        "    brown_out = [(1,7)]\n",
        "    non_terminal_reward = 0\n",
        "    terminal_reward = 10\n",
        "\n",
        "    base_kwargs =  {\"goal_location\": goal_location, \n",
        "            \"action_stochasticity\": action_stochasticity,\n",
        "            \"brown_in\": brown_in, \n",
        "            \"grey_in\": grey_in, \n",
        "            \"brown_out\": brown_out,\n",
        "            \"non_terminal_reward\": non_terminal_reward,\n",
        "            \"terminal_reward\": terminal_reward,\n",
        "            \"grey_out\": grey_out,}\n",
        "    \n",
        "    return base_kwargs\n",
        "\n",
        "base_kwargs = get_base_kwargs()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2WHRO2vGMhY"
      },
      "source": [
        "## Task 2.1 - Value Iteration\n",
        "Run value iteration on the environment and generate the policy and expected reward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtTqzVADFE7k"
      },
      "source": [
        "def value_iteration(env, gamma):\n",
        "    # Initial Values\n",
        "    values = np.zeros((10, 10))\n",
        "\n",
        "    # Initial policy\n",
        "    policy = np.empty((10, 10), object)\n",
        "    policy[:] = 'N' # Make all the policy values as 'N'\n",
        "\n",
        "    # Begin code here\n",
        "    value_grids = [] # Store all the J(s) grids at every iteration in this list\n",
        "    policies = []  # Store all the pi(s) grids at every iteration in this list\n",
        "\n",
        "    val = np.zeros((10,10))\n",
        "    pol = np.empty((10, 10), object)\n",
        "    pol[:] = 'N'\n",
        "\n",
        "  \n",
        "    l = -1\n",
        "    value_grid1 = np.zeros((10,10))\n",
        "    policy_grid1 = np.zeros((10, 10), np.int32)\n",
        "    while(True):\n",
        "      l = l+1\n",
        "      for i in range(10):\n",
        "        for j in range(10):\n",
        "              value = np.NINF\n",
        "              policy1 = ''\n",
        "              for actions in env.perpendicular_order :\n",
        "                  nspr = env.get_transition_probabilites_and_reward((i,j), actions)\n",
        "                  prob = deepcopy([ nspr[k][1] for k in range(len(nspr))])\n",
        "                  ns = deepcopy([(nspr[k][0][0],nspr[k][0][1]) for k in range(len(nspr))])\n",
        "                  rew = deepcopy([nspr[k][2] for k in range(len(nspr))])\n",
        "                  value_grid1[i][j] =  sum( [ prob[k]*(rew[k] + gamma*values[ns[k][0]][ns[k][1]]) for k in range(len(nspr))])\n",
        "\n",
        "                  if value != value_grid1[i][j]:\n",
        "                    value = deepcopy(max(value_grid1[i][j], value))\n",
        "                    if value == value_grid1[i][j]:\n",
        "                      policy1 = deepcopy(actions)\n",
        "\n",
        "              values[i][j] = deepcopy(value)\n",
        "              policy[i][j] = deepcopy(policy1)\n",
        "\n",
        "      value_grids.append(deepcopy(values))\n",
        "      policies.append(deepcopy(policy))\n",
        "\n",
        "      if l>=1:\n",
        "        converge = deepcopy(np.amax(np.absolute(value_grids[l]-value_grids[l-1])))\n",
        "        if converge < 1e-8:\n",
        "            #print(l)\n",
        "            #print(value_grids[l])           #Uncomment these lines to print the output\n",
        "            #print(policies[l])\n",
        "            break\n",
        "\n",
        "    \"\"\"for i in range(10):\n",
        "      for j in range(10):\n",
        "        values[i][j] = val[9-i][j]\n",
        "        policy[i][j] = pol[9-i][j] \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "    # Put your extra information needed for plots etc in this dictionary\n",
        "    extra_info = {}\n",
        "\n",
        "    # End code\n",
        "\n",
        "    # Do not change the number of output values\n",
        "    return {\"Values\": values, \"Policy\": policy}, extra_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2rZAEpLFE7l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8947fa4-e859-4a2e-9e58-0db731682562"
      },
      "source": [
        "env = GridEnv_HW2(**base_kwargs)\n",
        "res, extra_info = value_iteration(env, 0.7)\n",
        "\n",
        " # The rounding off is just for making print statement cleaner\n",
        "print(np.flipud(np.round(res['Values'], decimals=2)))\n",
        "print(np.flipud(res['Policy']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.1  0.15 0.24 0.37 0.56 0.86 1.29 0.12 8.68 0.  ]\n",
            " [0.13 0.2  0.31 0.5  0.81 1.31 2.12 3.43 5.75 8.95]\n",
            " [0.1  0.16 0.25 0.39 0.62 0.97 1.52 2.38 3.7  5.61]\n",
            " [0.07 0.11 0.17 0.26 0.41 0.64 0.99 1.54 2.38 3.52]\n",
            " [0.05 0.07 0.11 0.17 0.27 0.41 0.64 0.99 1.53 2.21]\n",
            " [0.03 0.05 0.07 0.11 0.17 0.27 0.41 0.64 0.98 1.39]\n",
            " [0.02 0.03 0.05 0.07 0.11 0.17 0.27 0.41 0.63 0.87]\n",
            " [0.03 0.02 0.03 0.05 0.07 0.11 0.17 0.27 0.4  0.55]\n",
            " [0.04 0.03 0.02 0.03 0.05 0.07 0.11 0.17 0.26 0.35]\n",
            " [0.07 0.04 0.03 0.02 0.03 0.05 0.07 0.11 0.17 0.22]]\n",
            "[['E' 'E' 'E' 'E' 'E' 'S' 'S' 'N' 'E' 'N']\n",
            " ['E' 'E' 'E' 'E' 'E' 'E' 'E' 'E' 'E' 'N']\n",
            " ['E' 'E' 'E' 'E' 'E' 'E' 'E' 'E' 'N' 'N']\n",
            " ['E' 'E' 'E' 'E' 'E' 'E' 'E' 'E' 'N' 'N']\n",
            " ['N' 'E' 'E' 'E' 'E' 'E' 'E' 'N' 'N' 'N']\n",
            " ['N' 'E' 'E' 'E' 'E' 'E' 'N' 'N' 'N' 'N']\n",
            " ['N' 'N' 'E' 'E' 'E' 'N' 'N' 'N' 'N' 'N']\n",
            " ['S' 'N' 'E' 'E' 'E' 'N' 'N' 'N' 'N' 'N']\n",
            " ['S' 'S' 'E' 'E' 'E' 'E' 'N' 'N' 'N' 'N']\n",
            " ['N' 'W' 'W' 'E' 'E' 'E' 'E' 'N' 'N' 'N']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_5iDbnlGV3Q"
      },
      "source": [
        "## Task 2.2 - Policy Iteration\n",
        "Run policy iteration on the environment and generate the policy and expected reward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMuG8uanFE7m"
      },
      "source": [
        "def policy_iteration(env, gamma):\n",
        "    # Initial Values\n",
        "    values = np.zeros((10, 10))\n",
        "\n",
        "    # Initial policy\n",
        "    policy = np.empty((10, 10), object)\n",
        "    policy[:] = 'N' # Make all the policy values as 'N'\n",
        "\n",
        "    # Begin code here  \n",
        "\n",
        "    value_grids = [] # Store all the J(s) grids at every iteration in this list\n",
        "    policies = []  # Store all the pi(s) grids at every iteration in this list\n",
        "\n",
        "\n",
        "    done = 0\n",
        "\n",
        "    while done == 0:  \n",
        "      done = 1\n",
        "      l = -1\n",
        "\n",
        "      while True:\n",
        "        delta = np.NINF\n",
        "        l = l+1\n",
        "        value_grid1 = np.zeros((10,10))\n",
        "        policy_grid1 = np.zeros((10, 10), np.int32)\n",
        "        J = 0\n",
        "        for i in range(10):\n",
        "          for j in range(10):\n",
        "                value = deepcopy(np.NINF)\n",
        "                nspr = deepcopy( env.get_transition_probabilites_and_reward((i,j), policy[i][j]) )\n",
        "                prob = deepcopy([ nspr[k][1] for k in range(len(nspr))])\n",
        "                ns = deepcopy([(nspr[k][0][0],nspr[k][0][1]) for k in range(len(nspr))])\n",
        "                rew = deepcopy([nspr[k][2] for k in range(len(nspr))])\n",
        "                J = values[i][j]\n",
        "                value_grid1[i][j] =  deepcopy( sum( [ prob[k]*(rew[k] + gamma*values[ns[k][0]][ns[k][1]]) for k in range(len(nspr))]) )\n",
        "                delta = deepcopy( max(delta, np.abs(J - value_grid1[i][j])) )\n",
        "        for i in range(10):\n",
        "          for j in range(10):\n",
        "                values[i][j] = deepcopy(value_grid1[i][j])\n",
        "        if delta < 1e-8:\n",
        "          break\n",
        "\n",
        "      b = np.empty((10, 10), object)\n",
        "      for i in range(10):\n",
        "        for j in range(10):\n",
        "              value = deepcopy(np.NINF)\n",
        "              policy1 = ''\n",
        "              b[i][j] = deepcopy(policy[i][j])\n",
        "              for actions in env.perpendicular_order :\n",
        "                  nspr = env.get_transition_probabilites_and_reward((i,j), actions)\n",
        "                  prob = deepcopy([ nspr[k][1] for k in range(len(nspr))])\n",
        "                  ns = deepcopy([(nspr[k][0][0],nspr[k][0][1]) for k in range(len(nspr))])\n",
        "                  rew = deepcopy([nspr[k][2] for k in range(len(nspr))])\n",
        "                  value_grid1[i][j] =  deepcopy( sum( [ prob[k]*(rew[k] + gamma*values[ns[k][0]][ns[k][1]]) for k in range(len(nspr))]) )\n",
        "\n",
        "                  if value != value_grid1[i][j]:\n",
        "                    value = deepcopy(max(value_grid1[i][j], value))\n",
        "                    if value == value_grid1[i][j]:\n",
        "                      policy1 = deepcopy(actions)\n",
        "              value_grid1[i][j] = deepcopy(value)\n",
        "              policy[i][j] = deepcopy(policy1)\n",
        "      \n",
        "      for i in range(10):\n",
        "        for j in range(10):\n",
        "              values[i][j] = deepcopy(value_grid1[i][j])\n",
        "      for i in range(10):\n",
        "        for j in range(10):\n",
        "              if b[i][j] != policy[i][j]:\n",
        "                done = 0\n",
        "      value_grids.append(deepcopy(values))\n",
        "      policies.append(deepcopy(policy))\n",
        "\n",
        "      \"\"\"  if l>=1:\n",
        "          converge = deepcopy(np.amax(np.absolute(value_grids[l]-value_grids[l-1])))\n",
        "          if converge < 1e-8:\n",
        "              #print(l)\n",
        "              #print(value_grids[l])           #Uncomment these lines to print the output\n",
        "              #print(policies[l])\n",
        "              break\"\"\"\n",
        "\n",
        "\n",
        "    # Put your extra information needed for plots etc in this dictionary\n",
        "    extra_info = {}\n",
        "    extra_info[\"Values\"] = value_grids\n",
        "    extra_info[\"Policy\"] = policies\n",
        "\n",
        "    # End code\n",
        "\n",
        "    # Do not change the number of output values\n",
        "    return {\"Values\": values, \"Policy\": policy}, extra_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aAhnGbZFE7m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d2fe2d-5537-49f8-af0f-185d7920e060"
      },
      "source": [
        "env = GridEnv_HW2(**base_kwargs)\n",
        "res, extra_info = policy_iteration(env, 0.7)\n",
        "\n",
        " # The rounding off is just for making print statement cleaner\n",
        "print(np.flipud(np.round(res['Values'], decimals=2)))\n",
        "print(np.flipud(res['Policy']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.1  0.15 0.24 0.37 0.56 0.86 1.29 0.12 8.68 0.  ]\n",
            " [0.13 0.2  0.31 0.5  0.81 1.31 2.12 3.43 5.75 8.95]\n",
            " [0.1  0.16 0.25 0.39 0.62 0.97 1.52 2.38 3.7  5.61]\n",
            " [0.07 0.11 0.17 0.26 0.41 0.64 0.99 1.54 2.38 3.52]\n",
            " [0.05 0.07 0.11 0.17 0.27 0.41 0.64 0.99 1.53 2.21]\n",
            " [0.03 0.05 0.07 0.11 0.17 0.27 0.41 0.64 0.98 1.39]\n",
            " [0.02 0.03 0.05 0.07 0.11 0.17 0.27 0.41 0.63 0.87]\n",
            " [0.03 0.02 0.03 0.05 0.07 0.11 0.17 0.27 0.4  0.55]\n",
            " [0.04 0.03 0.02 0.03 0.05 0.07 0.11 0.17 0.26 0.35]\n",
            " [0.07 0.04 0.03 0.02 0.03 0.05 0.07 0.11 0.17 0.22]]\n",
            "[['E' 'E' 'E' 'E' 'E' 'S' 'S' 'N' 'E' 'N']\n",
            " ['E' 'E' 'E' 'E' 'E' 'E' 'E' 'E' 'E' 'N']\n",
            " ['E' 'E' 'E' 'E' 'E' 'E' 'E' 'E' 'N' 'N']\n",
            " ['E' 'E' 'E' 'E' 'E' 'E' 'E' 'E' 'N' 'N']\n",
            " ['N' 'E' 'E' 'E' 'E' 'E' 'E' 'N' 'N' 'N']\n",
            " ['N' 'E' 'E' 'E' 'E' 'E' 'N' 'N' 'N' 'N']\n",
            " ['N' 'N' 'E' 'E' 'E' 'N' 'N' 'N' 'N' 'N']\n",
            " ['S' 'N' 'E' 'E' 'E' 'N' 'N' 'N' 'N' 'N']\n",
            " ['S' 'S' 'E' 'E' 'E' 'E' 'N' 'N' 'N' 'N']\n",
            " ['N' 'W' 'W' 'E' 'E' 'E' 'E' 'N' 'N' 'N']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GU6Gh6KPG7va"
      },
      "source": [
        "# Task 2.3 - TD Lambda\n",
        "\n",
        "Use the heuristic policy and implement TD lambda to find values on the gridworld"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPNFtV03FE7n"
      },
      "source": [
        "# The policy mentioned in the pdf to be used for TD lambda, do not modify this\n",
        "def heuristic_policy(env, state):\n",
        "    goal = env.goal_location\n",
        "    dx = goal[0] - state[0]\n",
        "    dy = goal[1] - state[1]\n",
        "    target_action = 'N'\n",
        "    if abs(dx) >= abs(dy):\n",
        "        direction = (np.sign(dx), 0)\n",
        "    else:\n",
        "        direction = (0, np.sign(dy))\n",
        "    for action, dir_val in env.actions.items():\n",
        "        if dir_val == direction:\n",
        "            target_action = action\n",
        "            break\n",
        "    return target_action"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv_uoHuJFE7n"
      },
      "source": [
        "def td_lambda(env, lamda, seeds):\n",
        "    alpha = 0.5\n",
        "    gamma = 0.7\n",
        "    N = len(seeds)\n",
        "    # Usage of input_policy\n",
        "    # heuristic_policy(env, state) -> action\n",
        "    example_action = heuristic_policy(env, (1,2)) # Returns 'N' if goal is (9,9)\n",
        "    value_grid = [] # Store all the J(s) grids at every iteration in this list\n",
        "\n",
        "    # Example of env.step\n",
        "    # env.step(state, action) -> Returns next_state, reward, is_terminal\n",
        "\n",
        "    # Initial values\n",
        "    values = np.zeros((10, 10))\n",
        "    es = np.zeros((10,10))\n",
        "\n",
        "    for episode_idx in range(N):\n",
        "         # Do not change this else the results will not match due to environment stochas\n",
        "        np.random.seed(seeds[episode_idx])\n",
        "        grey_in_loc = np.where(env.grid == 'grey_in')\n",
        "        state = grey_in_loc[0][0], grey_in_loc[1][0]\n",
        "        done = False\n",
        "        while not done:\n",
        "            action = heuristic_policy(env, state)\n",
        "            ns, rew, is_terminal = env.step(state, action) \n",
        "            # env.step is already taken inside the loop for you, \n",
        "            # Don't use env.step anywhere else in your code\n",
        "\n",
        "            # Begin code here\n",
        "            delta = rew - values[state[0]][state[1]] + gamma*values[ns[0]][ns[1]]\n",
        "            es[state[0]][state[1]] = es[state[0]][state[1]] + 1\n",
        "            for i in range(10):\n",
        "              for j in range(10):\n",
        "                values[i][j] = values[i][j] + alpha*delta*es[i][j]\n",
        "                es[i][j] = gamma*lamda*es[i][j]\n",
        "            a, b = ns\n",
        "            state = (a,b)\n",
        "            value_grid.append(values)\n",
        "            if is_terminal:\n",
        "              break\n",
        "\n",
        "\n",
        "    # Put your extra information needed for plots etc in this dictionary\n",
        "    extra_info = {}\n",
        "    extra_info[\"Values\"] = value_grid\n",
        "\n",
        "    # End code\n",
        "\n",
        "    # Do not change the number of output values\n",
        "    return {\"Values\": values}, extra_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1u7duRuFE7o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e4c9ea0-2ca0-4131-b135-804e636932e4"
      },
      "source": [
        "env = GridEnv_HW2(**base_kwargs)\n",
        "res, extra_info = td_lambda(env, lamda=0.5, seeds=np.arange(1000))\n",
        "\n",
        " # The rounding off is just for making print statement cleaner\n",
        "print(np.flipud(np.round(res['Values'], decimals=2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.    0.    0.01  0.02  0.03  0.06  0.08  0.11 10.    0.  ]\n",
            " [ 0.    0.    0.04  0.18  0.91  1.4   1.28  4.85  6.98  9.92]\n",
            " [ 0.    0.05  0.24  0.42  0.63  0.71  2.08  3.28  3.8   5.89]\n",
            " [ 0.02  0.08  0.21  0.31  0.48  0.82  1.29  1.66  2.2   3.39]\n",
            " [ 0.02  0.07  0.08  0.11  0.25  0.4   0.52  0.96  1.62  1.44]\n",
            " [ 0.02  0.04  0.05  0.1   0.16  0.23  0.38  0.57  1.08  0.97]\n",
            " [ 0.01  0.03  0.03  0.05  0.08  0.17  0.2   0.35  0.58  0.26]\n",
            " [ 0.    0.01  0.03  0.03  0.07  0.1   0.15  0.23  0.18  0.18]\n",
            " [ 0.    0.    0.01  0.01  0.03  0.03  0.1   0.15  0.16  0.  ]\n",
            " [ 0.12  0.    0.    0.    0.    0.01  0.01  0.11  0.13  0.  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYWxWZ3uHeC7"
      },
      "source": [
        "# Task 2.4 - TD Lamdba for multiple values of $\\lambda$\n",
        "\n",
        "Ideally this code should run as is"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13pTL6rIFE7o"
      },
      "source": [
        "# This cell is only for your subjective evaluation results, display the results as asked in the pdf\n",
        "# You can change it as you require, this code should run TD lamdba by default for different values of lambda\n",
        "\n",
        "lamda_values = np.arange(0, 100+5, 5)/100\n",
        "td_lamda_results = {}\n",
        "extra_info = {}\n",
        "for lamda in lamda_values:\n",
        "    env = GridEnv_HW2(**base_kwargs)\n",
        "    td_lamda_results[lamda], extra_info[lamda] = td_lambda(env, lamda,\n",
        "                                                           seeds=np.arange(1000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRslQDzQH7y1"
      },
      "source": [
        "# Generate Results ✅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI1Ypb9oIMOX"
      },
      "source": [
        "def get_results(kwargs):\n",
        "\n",
        "    gridenv = GridEnv_HW2(**kwargs)\n",
        "\n",
        "    policy_iteration_results = policy_iteration(gridenv, 0.7)[0]\n",
        "    value_iteration_results = value_iteration(gridenv, 0.7)[0]\n",
        "    td_lambda_results = td_lambda(env, 0.5, np.arange(1000))[0]\n",
        "\n",
        "    final_results = {}\n",
        "    final_results[\"policy_iteration\"] = policy_iteration_results\n",
        "    final_results[\"value_iteration\"] = value_iteration_results\n",
        "    final_results[\"td_lambda\"] = td_lambda_results\n",
        "\n",
        "    return final_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZMIwx_5FE7q"
      },
      "source": [
        "# Do not edit this cell, generate results with it as is\n",
        "if not os.path.exists(AICROWD_RESULTS_DIR):\n",
        "    os.mkdir(AICROWD_RESULTS_DIR)\n",
        "\n",
        "for params_file in os.listdir(DATASET_DIR):\n",
        "  kwargs = np.load(os.path.join(DATASET_DIR, params_file), allow_pickle=True).item()\n",
        "  results = get_results(kwargs)\n",
        "  idx = params_file.split('_')[-1][:-4]\n",
        "  np.save(os.path.join(AICROWD_RESULTS_DIR, 'results_' + idx), results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMtbDKwkKqTt"
      },
      "source": [
        "# Check your score on the public data\n",
        "\n",
        "This scores is not your final score, and it doesn't use the marks weightages. This is only for your reference of how arrays are matched and with what tolerance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WChErw_jFE7q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32811687-5fb7-4f4b-8bcb-59f116d23c4f"
      },
      "source": [
        "# Check your score on the given test cases (There are more private test cases not provided)\n",
        "target_folder = 'targets'\n",
        "result_folder = AICROWD_RESULTS_DIR\n",
        "\n",
        "def check_algo_match(results, targets):\n",
        "    if 'Policy' in results:\n",
        "        policy_match = results['Policy'] == targets['Policy']\n",
        "    else:\n",
        "        policy_match = True\n",
        "    # Reference https://numpy.org/doc/stable/reference/generated/numpy.allclose.html\n",
        "    rewards_match = np.allclose(results['Values'], targets['Values'], rtol=3)\n",
        "    equal = rewards_match and policy_match\n",
        "    return equal\n",
        "\n",
        "def check_score(target_folder, result_folder):\n",
        "    match = []\n",
        "    for out_file in os.listdir(result_folder):\n",
        "        res_file = os.path.join(result_folder, out_file)\n",
        "        results = np.load(res_file, allow_pickle=True).item()\n",
        "        idx = out_file.split('_')[-1][:-4]  # Extract the file number\n",
        "        target_file = os.path.join(target_folder, f\"targets_{idx}.npy\")\n",
        "        targets = np.load(target_file, allow_pickle=True).item()\n",
        "        algo_match = []\n",
        "        for k in targets:\n",
        "            algo_results = results[k]\n",
        "            algo_targets = targets[k]\n",
        "            algo_match.append(check_algo_match(algo_results, algo_targets))\n",
        "        match.append(np.mean(algo_match))\n",
        "    return np.mean(match)\n",
        "\n",
        "if os.path.exists(target_folder):\n",
        "    print(\"Shared data Score (normalized to 1):\", check_score(target_folder, result_folder))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shared data Score (normalized to 1): 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydLUplJZK9lB"
      },
      "source": [
        "## Display Results of TD lambda \n",
        "Display Results of TD lambda with lambda values from 0 to 1 with steps of 0.05\n",
        "\n",
        "Add code/text as required\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1EiJ6jkWF0-",
        "outputId": "d06e99ce-4305-4f6d-9d72-cc95f9bf851d"
      },
      "source": [
        "lamda_values = np.arange(0, 100+5, 5)/100\n",
        "td_lamda_results = {}\n",
        "extra_info = {}\n",
        "for lamda in lamda_values:\n",
        "    env = GridEnv_HW2(**base_kwargs)\n",
        "    td_lamda_results[lamda], extra_info[lamda] = td_lambda(env, lamda,\n",
        "                                                           seeds=np.arange(1000))\n",
        "    print(\"lamda :\", lamda)\n",
        "    print(np.round(td_lamda_results[lamda]['Values'], decimals=2), \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lamda : 0.0\n",
            "[[0.11 0.   0.   0.   0.   0.   0.   0.07 0.07 0.  ]\n",
            " [0.   0.   0.01 0.   0.01 0.   0.08 0.15 0.14 0.  ]\n",
            " [0.   0.01 0.02 0.02 0.04 0.07 0.13 0.22 0.19 0.07]\n",
            " [0.   0.02 0.04 0.04 0.07 0.12 0.14 0.33 0.55 0.  ]\n",
            " [0.01 0.03 0.05 0.09 0.14 0.22 0.3  0.57 0.99 0.35]\n",
            " [0.01 0.05 0.1  0.11 0.19 0.26 0.48 0.96 1.55 1.08]\n",
            " [0.   0.05 0.18 0.2  0.27 0.47 0.82 1.5  2.29 3.52]\n",
            " [0.   0.05 0.19 0.38 0.55 0.61 1.68 3.13 3.42 5.59]\n",
            " [0.   0.   0.03 0.09 0.69 1.09 1.56 4.79 6.95 9.91]\n",
            " [0.   0.   0.   0.01 0.03 0.05 0.08 0.1  9.99 0.  ]] \n",
            "\n",
            "lamda : 0.05\n",
            "[[0.11 0.   0.   0.   0.   0.   0.   0.07 0.08 0.  ]\n",
            " [0.   0.   0.01 0.   0.01 0.   0.09 0.16 0.15 0.  ]\n",
            " [0.   0.01 0.02 0.02 0.04 0.07 0.13 0.22 0.19 0.07]\n",
            " [0.   0.02 0.04 0.05 0.08 0.13 0.15 0.34 0.56 0.  ]\n",
            " [0.01 0.03 0.05 0.09 0.14 0.22 0.31 0.58 1.   0.4 ]\n",
            " [0.01 0.05 0.1  0.11 0.19 0.27 0.49 0.97 1.57 1.13]\n",
            " [0.01 0.05 0.18 0.2  0.29 0.5  0.87 1.51 2.28 3.55]\n",
            " [0.   0.05 0.2  0.38 0.55 0.62 1.72 3.15 3.45 5.61]\n",
            " [0.   0.   0.04 0.1  0.71 1.14 1.53 4.79 6.95 9.91]\n",
            " [0.   0.   0.   0.01 0.03 0.05 0.08 0.1  9.99 0.  ]] \n",
            "\n",
            "lamda : 0.1\n",
            "[[ 0.11  0.    0.    0.    0.    0.    0.    0.07  0.08  0.  ]\n",
            " [ 0.    0.    0.01  0.    0.02  0.01  0.09  0.16  0.15  0.  ]\n",
            " [ 0.    0.01  0.03  0.02  0.04  0.07  0.13  0.23  0.19  0.08]\n",
            " [ 0.    0.02  0.04  0.05  0.08  0.14  0.15  0.35  0.57  0.01]\n",
            " [ 0.01  0.03  0.05  0.09  0.13  0.23  0.32  0.59  1.02  0.46]\n",
            " [ 0.02  0.06  0.09  0.11  0.19  0.28  0.49  0.97  1.58  1.17]\n",
            " [ 0.01  0.05  0.18  0.21  0.31  0.53  0.92  1.52  2.27  3.57]\n",
            " [ 0.    0.05  0.21  0.38  0.55  0.63  1.76  3.16  3.49  5.64]\n",
            " [ 0.    0.    0.04  0.11  0.73  1.19  1.5   4.8   6.95  9.91]\n",
            " [ 0.    0.    0.    0.01  0.03  0.05  0.08  0.11 10.    0.  ]] \n",
            "\n",
            "lamda : 0.15\n",
            "[[ 0.11  0.    0.    0.    0.    0.    0.    0.08  0.09  0.  ]\n",
            " [ 0.    0.    0.01  0.    0.02  0.01  0.09  0.16  0.15  0.  ]\n",
            " [ 0.    0.01  0.03  0.02  0.04  0.08  0.14  0.23  0.19  0.08]\n",
            " [ 0.    0.02  0.04  0.05  0.08  0.14  0.16  0.35  0.58  0.03]\n",
            " [ 0.01  0.03  0.05  0.09  0.13  0.23  0.33  0.59  1.03  0.52]\n",
            " [ 0.02  0.06  0.09  0.11  0.19  0.29  0.5   0.98  1.6   1.21]\n",
            " [ 0.01  0.06  0.18  0.22  0.33  0.56  0.96  1.54  2.26  3.59]\n",
            " [ 0.    0.05  0.21  0.39  0.55  0.64  1.8   3.18  3.52  5.67]\n",
            " [ 0.    0.    0.04  0.11  0.75  1.23  1.48  4.81  6.96  9.91]\n",
            " [ 0.    0.    0.    0.01  0.03  0.05  0.08  0.11 10.    0.  ]] \n",
            "\n",
            "lamda : 0.2\n",
            "[[ 0.11  0.    0.    0.    0.    0.    0.    0.08  0.1   0.  ]\n",
            " [ 0.    0.    0.01  0.    0.02  0.01  0.09  0.16  0.16  0.  ]\n",
            " [ 0.    0.01  0.03  0.02  0.05  0.08  0.14  0.23  0.19  0.09]\n",
            " [ 0.    0.02  0.04  0.05  0.08  0.15  0.16  0.36  0.58  0.05]\n",
            " [ 0.01  0.04  0.05  0.09  0.13  0.23  0.34  0.6   1.04  0.58]\n",
            " [ 0.02  0.06  0.09  0.1   0.2   0.3   0.5   0.98  1.61  1.25]\n",
            " [ 0.01  0.06  0.18  0.23  0.34  0.6   1.01  1.55  2.26  3.59]\n",
            " [ 0.    0.05  0.22  0.39  0.56  0.65  1.85  3.19  3.56  5.7 ]\n",
            " [ 0.    0.    0.04  0.12  0.77  1.27  1.45  4.81  6.96  9.91]\n",
            " [ 0.    0.    0.    0.01  0.03  0.06  0.08  0.11 10.    0.  ]] \n",
            "\n",
            "lamda : 0.25\n",
            "[[ 0.11  0.    0.    0.    0.    0.    0.    0.09  0.1   0.  ]\n",
            " [ 0.    0.    0.01  0.    0.02  0.01  0.1   0.16  0.16  0.  ]\n",
            " [ 0.    0.01  0.03  0.02  0.05  0.08  0.14  0.24  0.19  0.09]\n",
            " [ 0.    0.02  0.03  0.05  0.08  0.15  0.17  0.36  0.58  0.07]\n",
            " [ 0.01  0.04  0.05  0.09  0.14  0.23  0.35  0.6   1.04  0.64]\n",
            " [ 0.02  0.06  0.09  0.1   0.2   0.32  0.51  0.98  1.62  1.29]\n",
            " [ 0.01  0.06  0.18  0.24  0.36  0.63  1.06  1.56  2.25  3.59]\n",
            " [ 0.    0.05  0.22  0.39  0.57  0.66  1.89  3.21  3.6   5.74]\n",
            " [ 0.    0.    0.04  0.13  0.8   1.31  1.42  4.82  6.96  9.91]\n",
            " [ 0.    0.    0.    0.01  0.03  0.06  0.08  0.11 10.    0.  ]] \n",
            "\n",
            "lamda : 0.3\n",
            "[[ 0.11  0.    0.    0.    0.    0.01  0.    0.09  0.11  0.  ]\n",
            " [ 0.    0.    0.01  0.    0.02  0.02  0.1   0.16  0.16  0.  ]\n",
            " [ 0.    0.01  0.03  0.03  0.05  0.09  0.14  0.24  0.19  0.1 ]\n",
            " [ 0.    0.02  0.03  0.05  0.08  0.16  0.17  0.36  0.59  0.1 ]\n",
            " [ 0.01  0.04  0.05  0.09  0.14  0.23  0.36  0.59  1.05  0.7 ]\n",
            " [ 0.02  0.06  0.09  0.1   0.21  0.33  0.51  0.98  1.62  1.32]\n",
            " [ 0.01  0.07  0.18  0.25  0.39  0.67  1.11  1.58  2.24  3.58]\n",
            " [ 0.    0.05  0.22  0.4   0.58  0.67  1.93  3.22  3.64  5.77]\n",
            " [ 0.    0.    0.04  0.14  0.82  1.34  1.39  4.83  6.97  9.91]\n",
            " [ 0.    0.    0.    0.02  0.03  0.06  0.08  0.11 10.    0.  ]] \n",
            "\n",
            "lamda : 0.35\n",
            "[[ 0.11  0.    0.    0.    0.    0.01  0.    0.1   0.12  0.  ]\n",
            " [ 0.    0.    0.01  0.    0.02  0.02  0.1   0.16  0.16  0.  ]\n",
            " [ 0.    0.01  0.03  0.03  0.06  0.09  0.15  0.24  0.19  0.12]\n",
            " [ 0.    0.03  0.03  0.05  0.08  0.16  0.18  0.36  0.59  0.13]\n",
            " [ 0.01  0.04  0.05  0.09  0.14  0.23  0.36  0.59  1.05  0.77]\n",
            " [ 0.02  0.06  0.09  0.1   0.22  0.35  0.51  0.98  1.62  1.36]\n",
            " [ 0.01  0.07  0.19  0.26  0.41  0.7   1.16  1.6   2.23  3.55]\n",
            " [ 0.    0.05  0.23  0.4   0.59  0.68  1.97  3.24  3.68  5.8 ]\n",
            " [ 0.    0.    0.04  0.15  0.85  1.36  1.37  4.83  6.97  9.91]\n",
            " [ 0.    0.    0.01  0.02  0.03  0.06  0.08  0.11 10.    0.  ]] \n",
            "\n",
            "lamda : 0.4\n",
            "[[ 0.11  0.    0.    0.    0.    0.01  0.    0.1   0.12  0.  ]\n",
            " [ 0.    0.    0.01  0.01  0.03  0.02  0.1   0.16  0.16  0.  ]\n",
            " [ 0.    0.01  0.03  0.03  0.06  0.09  0.15  0.23  0.19  0.13]\n",
            " [ 0.01  0.03  0.03  0.05  0.08  0.17  0.19  0.35  0.58  0.17]\n",
            " [ 0.02  0.04  0.05  0.1   0.15  0.23  0.37  0.58  1.06  0.84]\n",
            " [ 0.02  0.07  0.08  0.11  0.23  0.37  0.52  0.97  1.62  1.39]\n",
            " [ 0.02  0.07  0.19  0.28  0.43  0.74  1.2   1.61  2.22  3.51]\n",
            " [ 0.    0.05  0.23  0.41  0.6   0.69  2.01  3.25  3.72  5.83]\n",
            " [ 0.    0.    0.04  0.16  0.87  1.38  1.34  4.84  6.97  9.92]\n",
            " [ 0.    0.    0.01  0.02  0.03  0.06  0.08  0.11 10.    0.  ]] \n",
            "\n",
            "lamda : 0.45\n",
            "[[ 0.11  0.    0.    0.    0.    0.01  0.    0.1   0.12  0.  ]\n",
            " [ 0.    0.    0.01  0.01  0.03  0.03  0.1   0.16  0.16  0.  ]\n",
            " [ 0.    0.01  0.03  0.03  0.07  0.1   0.15  0.23  0.18  0.15]\n",
            " [ 0.01  0.03  0.03  0.05  0.08  0.17  0.19  0.35  0.58  0.21]\n",
            " [ 0.02  0.04  0.05  0.1   0.15  0.23  0.38  0.57  1.07  0.9 ]\n",
            " [ 0.02  0.07  0.08  0.11  0.24  0.38  0.52  0.97  1.62  1.41]\n",
            " [ 0.02  0.08  0.2   0.29  0.46  0.78  1.25  1.64  2.21  3.46]\n",
            " [ 0.    0.05  0.24  0.42  0.61  0.7   2.05  3.27  3.76  5.86]\n",
            " [ 0.    0.    0.04  0.17  0.89  1.4   1.31  4.84  6.98  9.92]\n",
            " [ 0.    0.    0.01  0.02  0.03  0.06  0.08  0.11 10.    0.  ]] \n",
            "\n",
            "lamda : 0.5\n",
            "[[ 0.12  0.    0.    0.    0.    0.01  0.01  0.11  0.13  0.  ]\n",
            " [ 0.    0.    0.01  0.01  0.03  0.03  0.1   0.15  0.16  0.  ]\n",
            " [ 0.    0.01  0.03  0.03  0.07  0.1   0.15  0.23  0.18  0.18]\n",
            " [ 0.01  0.03  0.03  0.05  0.08  0.17  0.2   0.35  0.58  0.26]\n",
            " [ 0.02  0.04  0.05  0.1   0.16  0.23  0.38  0.57  1.08  0.97]\n",
            " [ 0.02  0.07  0.08  0.11  0.25  0.4   0.52  0.96  1.62  1.44]\n",
            " [ 0.02  0.08  0.21  0.31  0.48  0.82  1.29  1.66  2.2   3.39]\n",
            " [ 0.    0.05  0.24  0.42  0.63  0.71  2.08  3.28  3.8   5.89]\n",
            " [ 0.    0.    0.04  0.18  0.91  1.4   1.28  4.85  6.98  9.92]\n",
            " [ 0.    0.    0.01  0.02  0.03  0.06  0.08  0.11 10.    0.  ]] \n",
            "\n",
            "lamda : 0.55\n",
            "[[1.200e-01 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e-02 1.000e-02\n",
            "  1.100e-01 1.300e-01 0.000e+00]\n",
            " [0.000e+00 0.000e+00 1.000e-02 1.000e-02 3.000e-02 4.000e-02 1.000e-01\n",
            "  1.500e-01 1.600e-01 0.000e+00]\n",
            " [0.000e+00 2.000e-02 3.000e-02 3.000e-02 8.000e-02 1.100e-01 1.500e-01\n",
            "  2.300e-01 1.700e-01 2.000e-01]\n",
            " [1.000e-02 3.000e-02 3.000e-02 5.000e-02 8.000e-02 1.700e-01 2.100e-01\n",
            "  3.500e-01 5.800e-01 3.100e-01]\n",
            " [2.000e-02 4.000e-02 5.000e-02 1.100e-01 1.700e-01 2.300e-01 3.900e-01\n",
            "  5.600e-01 1.090e+00 1.040e+00]\n",
            " [2.000e-02 7.000e-02 9.000e-02 1.100e-01 2.600e-01 4.200e-01 5.300e-01\n",
            "  9.600e-01 1.610e+00 1.460e+00]\n",
            " [2.000e-02 9.000e-02 2.200e-01 3.300e-01 5.100e-01 8.500e-01 1.340e+00\n",
            "  1.680e+00 2.190e+00 3.300e+00]\n",
            " [0.000e+00 5.000e-02 2.500e-01 4.300e-01 6.400e-01 7.200e-01 2.120e+00\n",
            "  3.300e+00 3.840e+00 5.920e+00]\n",
            " [0.000e+00 0.000e+00 4.000e-02 1.900e-01 9.300e-01 1.400e+00 1.250e+00\n",
            "  4.860e+00 6.980e+00 9.930e+00]\n",
            " [0.000e+00 0.000e+00 1.000e-02 2.000e-02 4.000e-02 6.000e-02 8.000e-02\n",
            "  1.000e-01 1.001e+01 0.000e+00]] \n",
            "\n",
            "lamda : 0.6\n",
            "[[1.300e-01 0.000e+00 0.000e+00 0.000e+00 0.000e+00 2.000e-02 1.000e-02\n",
            "  1.100e-01 1.300e-01 0.000e+00]\n",
            " [0.000e+00 0.000e+00 1.000e-02 1.000e-02 3.000e-02 4.000e-02 1.000e-01\n",
            "  1.500e-01 1.500e-01 0.000e+00]\n",
            " [0.000e+00 2.000e-02 3.000e-02 3.000e-02 8.000e-02 1.100e-01 1.500e-01\n",
            "  2.300e-01 1.700e-01 2.400e-01]\n",
            " [1.000e-02 3.000e-02 3.000e-02 6.000e-02 8.000e-02 1.800e-01 2.100e-01\n",
            "  3.500e-01 5.800e-01 3.700e-01]\n",
            " [2.000e-02 4.000e-02 5.000e-02 1.100e-01 1.700e-01 2.300e-01 3.900e-01\n",
            "  5.600e-01 1.100e+00 1.110e+00]\n",
            " [3.000e-02 8.000e-02 9.000e-02 1.200e-01 2.700e-01 4.400e-01 5.300e-01\n",
            "  9.500e-01 1.600e+00 1.480e+00]\n",
            " [3.000e-02 9.000e-02 2.300e-01 3.500e-01 5.400e-01 8.900e-01 1.380e+00\n",
            "  1.710e+00 2.190e+00 3.200e+00]\n",
            " [0.000e+00 6.000e-02 2.500e-01 4.400e-01 6.400e-01 7.300e-01 2.150e+00\n",
            "  3.310e+00 3.880e+00 5.950e+00]\n",
            " [0.000e+00 0.000e+00 4.000e-02 2.100e-01 9.400e-01 1.390e+00 1.220e+00\n",
            "  4.860e+00 6.990e+00 9.930e+00]\n",
            " [0.000e+00 0.000e+00 1.000e-02 2.000e-02 4.000e-02 6.000e-02 8.000e-02\n",
            "  1.000e-01 1.001e+01 0.000e+00]] \n",
            "\n",
            "lamda : 0.65\n",
            "[[1.300e-01 0.000e+00 0.000e+00 0.000e+00 0.000e+00 2.000e-02 2.000e-02\n",
            "  1.200e-01 1.200e-01 0.000e+00]\n",
            " [0.000e+00 0.000e+00 1.000e-02 1.000e-02 3.000e-02 5.000e-02 1.000e-01\n",
            "  1.400e-01 1.500e-01 0.000e+00]\n",
            " [0.000e+00 2.000e-02 3.000e-02 3.000e-02 8.000e-02 1.100e-01 1.500e-01\n",
            "  2.300e-01 1.600e-01 2.800e-01]\n",
            " [1.000e-02 3.000e-02 3.000e-02 6.000e-02 7.000e-02 1.700e-01 2.100e-01\n",
            "  3.500e-01 5.900e-01 4.300e-01]\n",
            " [2.000e-02 4.000e-02 5.000e-02 1.200e-01 1.800e-01 2.300e-01 4.000e-01\n",
            "  5.600e-01 1.120e+00 1.180e+00]\n",
            " [3.000e-02 8.000e-02 9.000e-02 1.200e-01 2.900e-01 4.600e-01 5.300e-01\n",
            "  9.500e-01 1.600e+00 1.490e+00]\n",
            " [3.000e-02 1.000e-01 2.400e-01 3.700e-01 5.700e-01 9.300e-01 1.420e+00\n",
            "  1.740e+00 2.180e+00 3.070e+00]\n",
            " [0.000e+00 6.000e-02 2.600e-01 4.400e-01 6.500e-01 7.400e-01 2.180e+00\n",
            "  3.330e+00 3.920e+00 5.980e+00]\n",
            " [0.000e+00 0.000e+00 4.000e-02 2.200e-01 9.500e-01 1.380e+00 1.180e+00\n",
            "  4.870e+00 6.990e+00 9.940e+00]\n",
            " [0.000e+00 0.000e+00 1.000e-02 2.000e-02 4.000e-02 6.000e-02 9.000e-02\n",
            "  1.000e-01 1.001e+01 0.000e+00]] \n",
            "\n",
            "lamda : 0.7\n",
            "[[1.400e-01 0.000e+00 0.000e+00 0.000e+00 0.000e+00 3.000e-02 2.000e-02\n",
            "  1.200e-01 1.200e-01 0.000e+00]\n",
            " [0.000e+00 0.000e+00 1.000e-02 1.000e-02 4.000e-02 6.000e-02 1.000e-01\n",
            "  1.400e-01 1.400e-01 0.000e+00]\n",
            " [0.000e+00 2.000e-02 3.000e-02 4.000e-02 9.000e-02 1.200e-01 1.500e-01\n",
            "  2.400e-01 1.500e-01 3.400e-01]\n",
            " [1.000e-02 3.000e-02 3.000e-02 6.000e-02 7.000e-02 1.700e-01 2.200e-01\n",
            "  3.600e-01 6.000e-01 4.900e-01]\n",
            " [2.000e-02 4.000e-02 5.000e-02 1.200e-01 1.900e-01 2.300e-01 4.000e-01\n",
            "  5.800e-01 1.140e+00 1.240e+00]\n",
            " [3.000e-02 8.000e-02 9.000e-02 1.300e-01 3.100e-01 4.800e-01 5.300e-01\n",
            "  9.500e-01 1.590e+00 1.490e+00]\n",
            " [3.000e-02 1.000e-01 2.600e-01 3.900e-01 6.100e-01 9.600e-01 1.450e+00\n",
            "  1.780e+00 2.180e+00 2.910e+00]\n",
            " [0.000e+00 6.000e-02 2.600e-01 4.400e-01 6.500e-01 7.400e-01 2.220e+00\n",
            "  3.340e+00 3.970e+00 6.000e+00]\n",
            " [0.000e+00 0.000e+00 4.000e-02 2.400e-01 9.500e-01 1.350e+00 1.150e+00\n",
            "  4.870e+00 7.000e+00 9.940e+00]\n",
            " [0.000e+00 0.000e+00 1.000e-02 2.000e-02 4.000e-02 6.000e-02 9.000e-02\n",
            "  9.000e-02 1.001e+01 0.000e+00]] \n",
            "\n",
            "lamda : 0.75\n",
            "[[1.500e-01 0.000e+00 0.000e+00 0.000e+00 0.000e+00 3.000e-02 2.000e-02\n",
            "  1.200e-01 1.200e-01 0.000e+00]\n",
            " [0.000e+00 0.000e+00 1.000e-02 1.000e-02 4.000e-02 7.000e-02 1.000e-01\n",
            "  1.400e-01 1.400e-01 0.000e+00]\n",
            " [1.000e-02 2.000e-02 3.000e-02 4.000e-02 9.000e-02 1.200e-01 1.500e-01\n",
            "  2.500e-01 1.500e-01 4.000e-01]\n",
            " [1.000e-02 3.000e-02 3.000e-02 6.000e-02 6.000e-02 1.700e-01 2.200e-01\n",
            "  3.800e-01 6.200e-01 5.700e-01]\n",
            " [2.000e-02 4.000e-02 5.000e-02 1.300e-01 2.100e-01 2.300e-01 4.000e-01\n",
            "  6.000e-01 1.170e+00 1.300e+00]\n",
            " [3.000e-02 9.000e-02 1.000e-01 1.400e-01 3.200e-01 5.000e-01 5.200e-01\n",
            "  9.600e-01 1.580e+00 1.490e+00]\n",
            " [3.000e-02 1.100e-01 2.700e-01 4.100e-01 6.400e-01 9.900e-01 1.490e+00\n",
            "  1.820e+00 2.180e+00 2.730e+00]\n",
            " [0.000e+00 7.000e-02 2.700e-01 4.400e-01 6.500e-01 7.500e-01 2.240e+00\n",
            "  3.350e+00 4.010e+00 6.030e+00]\n",
            " [0.000e+00 0.000e+00 4.000e-02 2.600e-01 9.500e-01 1.320e+00 1.110e+00\n",
            "  4.880e+00 7.000e+00 9.950e+00]\n",
            " [0.000e+00 0.000e+00 1.000e-02 3.000e-02 4.000e-02 6.000e-02 9.000e-02\n",
            "  9.000e-02 1.002e+01 0.000e+00]] \n",
            "\n",
            "lamda : 0.8\n",
            "[[1.600e-01 0.000e+00 0.000e+00 0.000e+00 0.000e+00 4.000e-02 3.000e-02\n",
            "  1.200e-01 1.100e-01 0.000e+00]\n",
            " [0.000e+00 0.000e+00 1.000e-02 1.000e-02 4.000e-02 8.000e-02 1.000e-01\n",
            "  1.500e-01 1.400e-01 0.000e+00]\n",
            " [1.000e-02 2.000e-02 3.000e-02 4.000e-02 9.000e-02 1.200e-01 1.400e-01\n",
            "  2.700e-01 1.500e-01 4.700e-01]\n",
            " [1.000e-02 3.000e-02 3.000e-02 6.000e-02 6.000e-02 1.600e-01 2.200e-01\n",
            "  4.100e-01 6.600e-01 6.500e-01]\n",
            " [2.000e-02 4.000e-02 6.000e-02 1.400e-01 2.200e-01 2.300e-01 4.000e-01\n",
            "  6.300e-01 1.210e+00 1.360e+00]\n",
            " [3.000e-02 1.000e-01 1.000e-01 1.400e-01 3.400e-01 5.200e-01 5.200e-01\n",
            "  9.700e-01 1.580e+00 1.480e+00]\n",
            " [4.000e-02 1.100e-01 2.900e-01 4.300e-01 6.700e-01 1.020e+00 1.520e+00\n",
            "  1.870e+00 2.190e+00 2.510e+00]\n",
            " [0.000e+00 8.000e-02 2.700e-01 4.400e-01 6.400e-01 7.600e-01 2.270e+00\n",
            "  3.370e+00 4.060e+00 6.050e+00]\n",
            " [0.000e+00 0.000e+00 4.000e-02 2.800e-01 9.400e-01 1.270e+00 1.080e+00\n",
            "  4.880e+00 7.010e+00 9.960e+00]\n",
            " [0.000e+00 0.000e+00 1.000e-02 3.000e-02 4.000e-02 7.000e-02 9.000e-02\n",
            "  9.000e-02 1.002e+01 0.000e+00]] \n",
            "\n",
            "lamda : 0.85\n",
            "[[1.800e-01 0.000e+00 0.000e+00 0.000e+00 0.000e+00 5.000e-02 3.000e-02\n",
            "  1.200e-01 1.000e-01 0.000e+00]\n",
            " [0.000e+00 0.000e+00 1.000e-02 1.000e-02 4.000e-02 9.000e-02 9.000e-02\n",
            "  1.600e-01 1.400e-01 0.000e+00]\n",
            " [1.000e-02 2.000e-02 3.000e-02 4.000e-02 8.000e-02 1.200e-01 1.400e-01\n",
            "  3.000e-01 1.500e-01 5.600e-01]\n",
            " [2.000e-02 3.000e-02 3.000e-02 7.000e-02 5.000e-02 1.500e-01 2.200e-01\n",
            "  4.600e-01 7.200e-01 7.400e-01]\n",
            " [2.000e-02 4.000e-02 6.000e-02 1.500e-01 2.300e-01 2.200e-01 4.000e-01\n",
            "  6.900e-01 1.250e+00 1.420e+00]\n",
            " [4.000e-02 1.100e-01 1.100e-01 1.500e-01 3.600e-01 5.400e-01 5.100e-01\n",
            "  9.900e-01 1.580e+00 1.460e+00]\n",
            " [4.000e-02 1.100e-01 3.000e-01 4.500e-01 7.100e-01 1.050e+00 1.540e+00\n",
            "  1.930e+00 2.200e+00 2.260e+00]\n",
            " [0.000e+00 9.000e-02 2.700e-01 4.300e-01 6.200e-01 7.700e-01 2.300e+00\n",
            "  3.380e+00 4.110e+00 6.060e+00]\n",
            " [0.000e+00 0.000e+00 3.000e-02 3.000e-01 9.200e-01 1.220e+00 1.040e+00\n",
            "  4.890e+00 7.010e+00 9.970e+00]\n",
            " [0.000e+00 0.000e+00 1.000e-02 3.000e-02 5.000e-02 7.000e-02 1.000e-01\n",
            "  9.000e-02 1.002e+01 0.000e+00]] \n",
            "\n",
            "lamda : 0.9\n",
            "[[1.900e-01 0.000e+00 0.000e+00 0.000e+00 0.000e+00 6.000e-02 3.000e-02\n",
            "  1.100e-01 1.000e-01 0.000e+00]\n",
            " [0.000e+00 0.000e+00 1.000e-02 1.000e-02 3.000e-02 1.100e-01 9.000e-02\n",
            "  1.700e-01 1.500e-01 0.000e+00]\n",
            " [1.000e-02 2.000e-02 3.000e-02 4.000e-02 8.000e-02 1.100e-01 1.300e-01\n",
            "  3.400e-01 1.600e-01 6.600e-01]\n",
            " [2.000e-02 4.000e-02 3.000e-02 7.000e-02 4.000e-02 1.400e-01 2.200e-01\n",
            "  5.200e-01 8.100e-01 8.300e-01]\n",
            " [2.000e-02 4.000e-02 7.000e-02 1.700e-01 2.500e-01 2.200e-01 4.000e-01\n",
            "  7.600e-01 1.310e+00 1.470e+00]\n",
            " [5.000e-02 1.200e-01 1.200e-01 1.600e-01 3.800e-01 5.600e-01 4.900e-01\n",
            "  1.020e+00 1.590e+00 1.420e+00]\n",
            " [5.000e-02 1.100e-01 3.200e-01 4.700e-01 7.400e-01 1.080e+00 1.570e+00\n",
            "  1.990e+00 2.220e+00 1.980e+00]\n",
            " [0.000e+00 1.000e-01 2.600e-01 4.100e-01 5.900e-01 7.700e-01 2.320e+00\n",
            "  3.390e+00 4.170e+00 6.080e+00]\n",
            " [0.000e+00 0.000e+00 3.000e-02 3.300e-01 9.000e-01 1.150e+00 1.010e+00\n",
            "  4.900e+00 7.020e+00 9.980e+00]\n",
            " [0.000e+00 0.000e+00 1.000e-02 3.000e-02 5.000e-02 7.000e-02 1.100e-01\n",
            "  1.000e-01 1.003e+01 0.000e+00]] \n",
            "\n",
            "lamda : 0.95\n",
            "[[2.100e-01 0.000e+00 0.000e+00 0.000e+00 0.000e+00 8.000e-02 2.000e-02\n",
            "  9.000e-02 1.000e-01 0.000e+00]\n",
            " [0.000e+00 0.000e+00 1.000e-02 1.000e-02 2.000e-02 1.400e-01 8.000e-02\n",
            "  1.900e-01 1.700e-01 0.000e+00]\n",
            " [1.000e-02 2.000e-02 2.000e-02 4.000e-02 6.000e-02 1.000e-01 1.300e-01\n",
            "  4.100e-01 1.700e-01 7.700e-01]\n",
            " [2.000e-02 4.000e-02 3.000e-02 7.000e-02 4.000e-02 1.400e-01 2.200e-01\n",
            "  6.100e-01 9.400e-01 9.300e-01]\n",
            " [2.000e-02 4.000e-02 7.000e-02 1.800e-01 2.600e-01 2.200e-01 4.000e-01\n",
            "  8.500e-01 1.370e+00 1.510e+00]\n",
            " [6.000e-02 1.300e-01 1.300e-01 1.700e-01 4.000e-01 5.800e-01 4.800e-01\n",
            "  1.070e+00 1.590e+00 1.380e+00]\n",
            " [6.000e-02 1.000e-01 3.300e-01 4.800e-01 7.800e-01 1.100e+00 1.590e+00\n",
            "  2.070e+00 2.250e+00 1.650e+00]\n",
            " [0.000e+00 1.300e-01 2.500e-01 3.800e-01 5.500e-01 7.800e-01 2.340e+00\n",
            "  3.400e+00 4.230e+00 6.090e+00]\n",
            " [0.000e+00 0.000e+00 3.000e-02 3.600e-01 8.700e-01 1.080e+00 9.800e-01\n",
            "  4.900e+00 7.020e+00 9.990e+00]\n",
            " [0.000e+00 0.000e+00 1.000e-02 4.000e-02 6.000e-02 8.000e-02 1.200e-01\n",
            "  1.100e-01 1.003e+01 0.000e+00]] \n",
            "\n",
            "lamda : 1.0\n",
            "[[2.200e-01 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e-01 0.000e+00\n",
            "  5.000e-02 1.100e-01 0.000e+00]\n",
            " [0.000e+00 0.000e+00 0.000e+00 1.000e-02 1.000e-02 1.700e-01 7.000e-02\n",
            "  2.200e-01 2.100e-01 0.000e+00]\n",
            " [1.000e-02 3.000e-02 1.000e-02 4.000e-02 3.000e-02 7.000e-02 1.300e-01\n",
            "  4.900e-01 2.000e-01 8.900e-01]\n",
            " [3.000e-02 5.000e-02 3.000e-02 6.000e-02 3.000e-02 1.400e-01 2.200e-01\n",
            "  7.100e-01 1.110e+00 1.050e+00]\n",
            " [1.000e-02 5.000e-02 8.000e-02 2.000e-01 2.800e-01 2.200e-01 4.100e-01\n",
            "  9.600e-01 1.440e+00 1.560e+00]\n",
            " [8.000e-02 1.400e-01 1.400e-01 1.800e-01 4.200e-01 6.000e-01 4.600e-01\n",
            "  1.120e+00 1.610e+00 1.330e+00]\n",
            " [8.000e-02 9.000e-02 3.400e-01 4.900e-01 8.100e-01 1.120e+00 1.600e+00\n",
            "  2.150e+00 2.280e+00 1.280e+00]\n",
            " [0.000e+00 1.600e-01 2.200e-01 3.400e-01 5.000e-01 7.800e-01 2.360e+00\n",
            "  3.410e+00 4.290e+00 6.090e+00]\n",
            " [0.000e+00 0.000e+00 2.000e-02 3.900e-01 8.300e-01 9.900e-01 9.500e-01\n",
            "  4.910e+00 7.030e+00 1.000e+01]\n",
            " [0.000e+00 0.000e+00 1.000e-02 4.000e-02 6.000e-02 9.000e-02 1.400e-01\n",
            "  1.300e-01 1.004e+01 0.000e+00]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3ZtRjtWKzgp"
      },
      "source": [
        "# Subjective questions\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PGVaZh-LWIz"
      },
      "source": [
        "## 2.a Value Iteration vs Policy Iteration\n",
        "\n",
        "\n",
        "1.   Compare value iteration and policy iteration for states Brown in, Brown Out, Grey out and Grey In \n",
        "2.   Which one converges faster and why\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4_lK5i6M3Xz"
      },
      "source": [
        "## 2.b How changing $\\lambda$ affecting TD Lambda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roJt93YRMCKH"
      },
      "source": [
        "## 2.c Policy iteration error curve\n",
        "Plot error curve of $J_i$ vs iteration $i$ for policy iteration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "_urFLdXOZsfR",
        "outputId": "ce4c3d49-953e-4dfa-d23b-aeabc94d4be0"
      },
      "source": [
        "env = GridEnv_HW2(**base_kwargs)\n",
        "res, extra_info = policy_iteration(env, 0.7)\n",
        "\n",
        "value_grid = extra_info[\"Values\"]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "diffs = []\n",
        "for ii in range(len(value_grid)-1):\n",
        "    diff = np.linalg.norm(value_grid[ii+1]-value_grid[ii]) \n",
        "    diffs.append(diff)\n",
        "plt.plot(diffs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fcef64a2250>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD-SUvNOMeR7"
      },
      "source": [
        "## 2.d TD Lamdba error curve\n",
        "Plot error curve of $J_i$ vs iteration $i$ for TD Lambda for $\\lambda = [0, 0.25, 0.5, 0.75, 1]$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "gPVhTdhScm_u",
        "outputId": "e117d106-35ba-4f3e-9ad6-96ed75ff13f3"
      },
      "source": [
        "env = GridEnv_HW2(**base_kwargs)\n",
        "res, extra_info = td_lambda(env, lamda=0.5, seeds=np.arange(1000))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for lamda in [0,0.25,0.5,0.75,1]:\n",
        "  diffs = []\n",
        "  res, extra_info = td_lambda(env, lamda, seeds=np.arange(1000))\n",
        "  value_grid = extra_info[\"Values\"]\n",
        "  for ii in range(len(value_grid)-1):\n",
        "      diff = np.sqrt((value_grid[ii+1] - value_grid[ii])/100) \n",
        "      diffs.append(diff)\n",
        "  plt.plot(diffs)\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c835a935de36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridEnv_HW2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbase_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtd_lambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'GridEnv_HW2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxQpr5ADFE7q"
      },
      "source": [
        "# Submit to AIcrowd 🚀"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUh6vY-1FE7q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f80a6291-3d16-497b-dd3f-7a2b5fbf1004"
      },
      "source": [
        "!DATASET_PATH=$AICROWD_DATASET_PATH aicrowd notebook submit --no-verify -c iit-m-rl-assignment-2-gridworld -a assets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: No assets directory at assets... Creating one...\n",
            "No jupyter lab module found. Using jupyter notebook.\n",
            "Using notebook: /content/Copy%20of%20IITM_Assignment_2_Gridworld_Release.ipynb for submission...\n",
            "\u001b[1;34mMounting Google Drive 💾\u001b[0m\n",
            "Your Google Drive will be mounted to access the colab notebook\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/1AY0e-g50SF-4BMysmWaOKL6paNMEWS1M-0pjHa7lVMzrmf2wWdFtWLmiiz8\n",
            "Mounted at /content/drive\n",
            "No jupyter lab module found. Using jupyter notebook.\n",
            "Scrubbing API keys from the notebook...\n",
            "Collecting notebook...\n",
            "No jupyter lab module found. Using jupyter notebook.\n",
            "\u001b[2K\u001b[1;34msubmission.zip\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.0%\u001b[0m • \u001b[32m28.7/27.1 KB\u001b[0m • \u001b[31m2.3 MB/s\u001b[0m • \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h                                                             ╭─────────────────────────╮                                                             \n",
            "                                                             │ \u001b[1mSuccessfully submitted!\u001b[0m │                                                             \n",
            "                                                             ╰─────────────────────────╯                                                             \n",
            "\u001b[3m                                                                   Important links                                                                   \u001b[0m\n",
            "┌──────────────────┬────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
            "│  This submission │ https://www.aicrowd.com/challenges/iit-m-assignment-2/problems/iit-m-rl-assignment-2-gridworld/submissions/132135              │\n",
            "│                  │                                                                                                                                │\n",
            "│  All submissions │ https://www.aicrowd.com/challenges/iit-m-assignment-2/problems/iit-m-rl-assignment-2-gridworld/submissions?my_submissions=true │\n",
            "│                  │                                                                                                                                │\n",
            "│      Leaderboard │ https://www.aicrowd.com/challenges/iit-m-assignment-2/problems/iit-m-rl-assignment-2-gridworld/leaderboards                    │\n",
            "│                  │                                                                                                                                │\n",
            "│ Discussion forum │ https://discourse.aicrowd.com/c/iit-m-assignment-2                                                                             │\n",
            "│                  │                                                                                                                                │\n",
            "│   Challenge page │ https://www.aicrowd.com/challenges/iit-m-assignment-2/problems/iit-m-rl-assignment-2-gridworld                                 │\n",
            "└──────────────────┴────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7mg_xZGFATn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
