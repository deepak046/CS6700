{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit (conda)",
      "metadata": {
        "interpreter": {
          "hash": "828b2d2e90c34517c0f3db151137e4812c232f0241304c27576ea4a0014563c4"
        }
      }
    },
    "colab": {
      "name": "Copy of IITM_RL_DP_ASSIGNMENT_v1",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXoLHrjbjNJp"
      },
      "source": [
        "<div style=\"text-align: center\">\n",
        "  <a href=\"https://www.aicrowd.com/challenges/rl-taxi\"><img alt=\"AIcrowd\" src=\"https://images.aicrowd.com/raw_images/challenges/banner_file/759/d9540ebbd506b68a5ff2.jpg\"></a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rBlqB-7jSaG"
      },
      "source": [
        "# What is the notebook about?\n",
        "\n",
        "## Problem - DP Algorithm\n",
        "This problem deals with a taxi driver with multiple actions in different cities. The tasks you have to do are:\n",
        "- Implement DP Algorithm to find the optimal sequence for the taxi driver\n",
        "- Find optimal policies for sequences of varying lengths\n",
        "- Explain a variation on the policy\n",
        "\n",
        "# How to use this notebook? üìù\n",
        "\n",
        "- This is a shared template and any edits you make here will not be saved. **You\n",
        "should make a copy in your own drive**. Click the \"File\" menu (top-left), then \"Save a Copy in Drive\". You will be working in your copy however you like.\n",
        "\n",
        "<p style=\"text-align: center\"><img src=\"https://gitlab.aicrowd.com/aicrowd/assets/-/raw/master/notebook/aicrowd_notebook_submission_flow.png?inline=false\" alt=\"notebook overview\" style=\"width: 650px;\"/></p>\n",
        "\n",
        "- **Update the config parameters**. You can define the common variables here\n",
        "\n",
        "Variable | Description\n",
        "--- | ---\n",
        "`AICROWD_DATASET_PATH` | Path to the file containing test data. This should be an absolute path.\n",
        "`AICROWD_RESULTS_DIR` | Path to write the output to.\n",
        "`AICROWD_ASSETS_DIR` | In case your notebook needs additional files (like model weights, etc.,), you can add them to a directory and specify the path to the directory here (please specify relative path). The contents of this directory will be sent to AIcrowd for evaluation.\n",
        "`AICROWD_API_KEY` | In order to submit your code to AIcrowd, you need to provide your account's API key. This key is available at https://www.aicrowd.com/participants/me\n",
        "\n",
        "- **Installing packages**. Please use the [Install packages üóÉ](#install-packages-) section to install the packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr2_Itu2jmYu"
      },
      "source": [
        "# Setup AIcrowd Utilities üõ†\n",
        "\n",
        "We use this to bundle the files for submission and create a submission on AIcrowd. Do not edit this block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kriIY9ntvLQD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3954b8b8-b576-48ba-a94f-e475cef865d5"
      },
      "source": [
        "!pip install -U git+https://gitlab.aicrowd.com/aicrowd/aicrowd-cli.git@notebook-submission-v2 > /dev/null "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Running command git clone -q https://gitlab.aicrowd.com/aicrowd/aicrowd-cli.git /tmp/pip-req-build-49rstwd4\n",
            "  Running command git checkout -b notebook-submission-v2 --track origin/notebook-submission-v2\n",
            "  Switched to a new branch 'notebook-submission-v2'\n",
            "  Branch 'notebook-submission-v2' set up to track remote branch 'notebook-submission-v2' from 'origin'.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecFpLP6avMok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f74a130f-d2e2-4ef8-9582-f58a30067c4d"
      },
      "source": [
        "%load_ext aicrowd.magic "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The aicrowd.magic extension is already loaded. To reload it, use:\n",
            "  %reload_ext aicrowd.magic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tpalq6zjo3X"
      },
      "source": [
        "# AIcrowd Runtime Configuration üß∑\n",
        "\n",
        "Define configuration parameters. Please include any files needed for the notebook to run under `ASSETS_DIR`. We will copy the contents of this directory to your final submission file üôÇ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up8mk6fhvOub"
      },
      "source": [
        "import os\n",
        "\n",
        "AICROWD_DATASET_PATH = os.getenv(\"DATASET_PATH\", os.getcwd()+\"/40746340-4151-4921-8496-be10b3f8f5cf_hw2_q1.zip\")\n",
        "AICROWD_RESULTS_DIR = os.getenv(\"OUTPUTS_DIR\", \"results\")\n",
        "API_KEY = \"89dd325ae9efc70f942ba512e985ca0f\" #Get your API key from https://www.aicrowd.com/participants/me"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2w1nVPDj9Uj"
      },
      "source": [
        "# Download dataset files üì≤"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV9xReqhvVNt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c17f4397-b85d-449b-933a-f9c88dda2e34"
      },
      "source": [
        "!aicrowd login --api-key $API_KEY\n",
        "!aicrowd dataset download -c rl-taxi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mAPI Key valid\u001b[0m\n",
            "\u001b[32mSaved API Key successfully!\u001b[0m\n",
            "40746340-4151-4921-8496-be10b3f8f5cf_hw2_q1.zip: 100% 3.03k/3.03k [00:00<00:00, 147kB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTYP6MFKvXCM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6834d07b-025a-40fd-f5eb-011c348731a1"
      },
      "source": [
        "!unzip -q $AICROWD_DATASET_PATH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace hw2_q1/inputs/env_params_0.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace hw2_q1/sample_results/sample_results_0.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace hw2_q1/targets/targets_0.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vijz0kfaKzmw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eab0e35f-e927-430c-99db-8c7efc7342bc"
      },
      "source": [
        "DATASET_DIR = 'hw2_q1/'\n",
        "!mkdir {DATASET_DIR}results/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‚Äòhw2_q1/results/‚Äô: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTeWFlWukTob"
      },
      "source": [
        "# Install packages üóÉ\n",
        "\n",
        "Please add all pacakage installations in this section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV5fXPkYkUxz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJbm42p_kWRG"
      },
      "source": [
        "# Import packages üíª"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geEOnXHeK4oQ"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from copy import deepcopy\n",
        "# ADD ANY IMPORTS YOU WANT HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL3_9MAk5cqv"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class TaxiEnv_HW2:\n",
        "    def __init__(self, states, actions, probabilities, rewards):\n",
        "        self.possible_states = states\n",
        "        self._possible_actions = {st: ac for st, ac in zip(states, actions)}\n",
        "        self._ride_probabilities = {st: pr for st, pr in zip(states, probabilities)}\n",
        "        self._ride_rewards = {st: rw for st, rw in zip(states, rewards)}\n",
        "        self._verify()\n",
        "\n",
        "    def _check_state(self, state):\n",
        "        assert state in self.possible_states, \"State %s is not a valid state\" % state\n",
        "\n",
        "    def _verify(self):\n",
        "        \"\"\" \n",
        "        Verify that data conditions are met:\n",
        "        Number of actions matches shape of next state and actions\n",
        "        Every probability distribution adds up to 1 \n",
        "        \"\"\"\n",
        "        ns = len(self.possible_states)\n",
        "        for state in self.possible_states:\n",
        "            ac = self._possible_actions[state]\n",
        "            na = len(ac)\n",
        "\n",
        "            rp = self._ride_probabilities[state]\n",
        "            assert np.all(rp.shape == (na, ns)), \"Probabilities shape mismatch\"\n",
        "        \n",
        "            rr = self._ride_rewards[state]\n",
        "            assert np.all(rr.shape == (na, ns)), \"Rewards shape mismatch\"\n",
        "\n",
        "            assert np.allclose(rp.sum(axis=1), 1), \"Probabilities don't add up to 1\"\n",
        "\n",
        "    def possible_actions(self, state):\n",
        "        \"\"\" Return all possible actions from a given state \"\"\"\n",
        "        self._check_state(state)\n",
        "        return self._possible_actions[state]\n",
        "\n",
        "    def ride_probabilities(self, state, action):\n",
        "        \"\"\" \n",
        "        Returns all possible ride probabilities from a state for a given action\n",
        "        For every action a list with the returned with values in the same order as self.possible_states\n",
        "        \"\"\"\n",
        "        actions = self.possible_actions(state)\n",
        "        ac_idx = actions.index(action)\n",
        "        return self._ride_probabilities[state][ac_idx]\n",
        "\n",
        "    def ride_rewards(self, state, action):\n",
        "        actions = self.possible_actions(state)\n",
        "        ac_idx = actions.index(action)\n",
        "        return self._ride_rewards[state][ac_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APNUuTHK5cqw"
      },
      "source": [
        "# Examples of using the environment functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8BwZY8Z5cqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2aee32c-a596-4219-f1c9-5fd6bc5ba98a"
      },
      "source": [
        "def check_taxienv():\n",
        "    # These are the values as used in the pdf, but they may be changed during submission, so do not hardcode anything\n",
        "\n",
        "    states = ['A', 'B', 'C']\n",
        "\n",
        "    actions = [['1','2','3'], ['1','2'], ['1','2','3']]\n",
        "\n",
        "    probs = [np.array([[1/2,  1/4,  1/4],\n",
        "                    [1/16, 3/4,  3/16],\n",
        "                    [1/4,  1/8,  5/8]]),\n",
        "\n",
        "            np.array([[1/2,   0,     1/2],\n",
        "                    [1/16,  7/8,  1/16]]),\n",
        "\n",
        "            np.array([[1/4,  1/4,  1/2],\n",
        "                    [1/8,  3/4,  1/8],\n",
        "                    [3/4,  1/16, 3/16]]),]\n",
        "\n",
        "    rewards = [np.array([[10,  4,  8],\n",
        "                        [ 8,  2,  4],\n",
        "                        [ 4,  6,  4]]),\n",
        "    \n",
        "            np.array([[14,  0, 18],\n",
        "                        [ 8, 16,  8]]),\n",
        "    \n",
        "            np.array([[10,  2,  8],\n",
        "                        [6,   4,  2],\n",
        "                        [4,   0,  8]]),]\n",
        "\n",
        "\n",
        "    env = TaxiEnv_HW2(states, actions, probs, rewards)\n",
        "    print(\"All possible states\", env.possible_states)\n",
        "    print(\"All possible actions from state B\", env.possible_actions('B'))\n",
        "    print(\"Ride probabilities from state A with action 2\", env.ride_probabilities('A', '2'))\n",
        "    print(\"Ride rewards from state C with action 3\", env.ride_rewards('C', '3'))\n",
        "\n",
        "check_taxienv()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All possible states ['A', 'B', 'C']\n",
            "All possible actions from state B ['1', '2']\n",
            "Ride probabilities from state A with action 2 [0.0625 0.75   0.1875]\n",
            "Ride rewards from state C with action 3 [4 0 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh6g_1u05cqx"
      },
      "source": [
        "# Task 1 - DP Algorithm implementation\n",
        "Implement your DP algorithm that takes the starting state and sequence length\n",
        "and return the expected reward for the policy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMYcbfVq5cqx"
      },
      "source": [
        "def dp_solve(taxienv):\n",
        "    ## Implement the DP algorithm for the taxienv\n",
        "    states = taxienv.possible_states\n",
        "    values = {s: 0 for s in states}\n",
        "    policy = {s: '0' for s in states}\n",
        "    all_values = [] # Append the \"values\" dictionary to this after each update\n",
        "    all_policies = [] # Append the \"policy\" dictionary to this after each update\n",
        "    # Note: The sequence length is always N=10\n",
        "    \n",
        "    # ADD YOUR CODE BELOW - DO NOT EDIT ABOVE THIS LINE\n",
        "    N = 10\n",
        "    for i in range(N-1,-1,-1):\n",
        "        \n",
        "        for st in states:\n",
        "\n",
        "            value1 = np.NINF\n",
        "            policy1 = ''\n",
        "            for action in taxienv.possible_actions(st):\n",
        "               if i == N - 1:\n",
        "                  value = sum([(taxienv.ride_probabilities(st,action))[k]*(taxienv.ride_rewards(st,action))[k] for k in range(len(taxienv.ride_probabilities(st,action)))])                 \n",
        "\n",
        "               else:\n",
        "                  value = sum([(taxienv.ride_probabilities(st,action))[k]*((taxienv.ride_rewards(st,action))[k] + list(all_values[N-i-2].values())[k]) for k in range(len(taxienv.ride_probabilities(st,action)))])\n",
        "                                \n",
        "               value1 = deepcopy(max(value,value1))\n",
        "               if value1 == value:\n",
        "                  policy1 = deepcopy(action) \n",
        "            \n",
        "            values[st] = deepcopy(value1)\n",
        "            policy[st] = deepcopy(policy1)\n",
        "\n",
        "        all_values.append(deepcopy(values))\n",
        "        all_policies.append(deepcopy(policy))    \n",
        "\n",
        "\n",
        "    # DO NOT EDIT BELOW THIS LINE\n",
        "    results = {\"Expected Reward\": all_values, \"Polcies\": all_policies}\n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us8AYNVXISv1"
      },
      "source": [
        "## Here is an example of what the \"results\" output from value_iter function should look like\n",
        "\n",
        "Ofcourse, it won't be all zeros\n",
        "``` python \n",
        "{'Expected Reward': [{'A': 0, 'B': 0, 'C': 0},\n",
        "  {'A': 0, 'B': 0, 'C': 0},\n",
        "  {'A': 0, 'B': 0, 'C': 0},\n",
        "  {'A': 0, 'B': 0, 'C': 0},\n",
        "  {'A': 0, 'B': 0, 'C': 0},\n",
        "  {'A': 0, 'B': 0, 'C': 0},\n",
        "  {'A': 0, 'B': 0, 'C': 0},\n",
        "  {'A': 0, 'B': 0, 'C': 0},\n",
        "  {'A': 0, 'B': 0, 'C': 0},\n",
        "  {'A': 0, 'B': 0, 'C': 0}],\n",
        " 'Polcies': [{'A': '0', 'B': '0', 'C': '0'},\n",
        "  {'A': '0', 'B': '0', 'C': '0'},\n",
        "  {'A': '0', 'B': '0', 'C': '0'},\n",
        "  {'A': '0', 'B': '0', 'C': '0'},\n",
        "  {'A': '0', 'B': '0', 'C': '0'},\n",
        "  {'A': '0', 'B': '0', 'C': '0'},\n",
        "  {'A': '0', 'B': '0', 'C': '0'},\n",
        "  {'A': '0', 'B': '0', 'C': '0'},\n",
        "  {'A': '0', 'B': '0', 'C': '0'},\n",
        "  {'A': '0', 'B': '0', 'C': '0'}]}\n",
        "\n",
        "  ```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ct5_WU1meeo"
      },
      "source": [
        "if not os.path.exists(AICROWD_RESULTS_DIR):\n",
        "  os.mkdir(AICROWD_RESULTS_DIR)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AblFN9zNIjwV"
      },
      "source": [
        "# DO NOT EDIT THIS CELL, DURING EVALUATION THE DATASET DIR WILL CHANGE\n",
        "input_dir = os.path.join(DATASET_DIR, 'inputs')\n",
        "for params_file in os.listdir(input_dir):\n",
        "  kwargs = np.load(os.path.join(input_dir, params_file), allow_pickle=True).item()\n",
        "\n",
        "  env = TaxiEnv_HW2(**kwargs)\n",
        "\n",
        "  results = dp_solve(env)\n",
        "  idx = params_file.split('_')[-1][:-4]\n",
        "  np.save(os.path.join(AICROWD_RESULTS_DIR, 'results_' + idx), results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fswnLXrXL2wh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f7397e1-f591-4d59-f6cb-9c9d171c7671"
      },
      "source": [
        "##¬†Modify this code to show the results for the policy and expected rewards properly\n",
        "print(results)\n",
        "Results = results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Expected Reward': [{'A': 8.0, 'B': 16.0, 'C': 7.0}, {'A': 17.75, 'B': 29.9375, 'C': 17.875}, {'A': 29.6640625, 'B': 43.421875, 'C': 30.90625}, {'A': 42.96533203125, 'B': 56.77978515625, 'C': 44.1376953125}, {'A': 56.295989990234375, 'B': 70.12625122070312, 'C': 57.47271728515625}, {'A': 69.63932228088379, 'B': 83.47101402282715, 'C': 70.81577682495117}, {'A': 82.98367631435394, 'B': 96.81558096408844, 'C': 84.16014790534973}, {'A': 96.32819322496653, 'B': 110.16012235730886, 'C': 97.50466375052929}, {'A': 109.6727282977663, 'B': 123.50466062361374, 'C': 110.84919888991863}, {'A': 123.01726577818044, 'B': 136.84919849489233, 'C': 124.19373636617092}], 'Polcies': [{'A': '1', 'B': '1', 'C': '1'}, {'A': '1', 'B': '2', 'C': '2'}, {'A': '2', 'B': '2', 'C': '2'}, {'A': '2', 'B': '2', 'C': '2'}, {'A': '2', 'B': '2', 'C': '2'}, {'A': '2', 'B': '2', 'C': '2'}, {'A': '2', 'B': '2', 'C': '2'}, {'A': '2', 'B': '2', 'C': '2'}, {'A': '2', 'B': '2', 'C': '2'}, {'A': '2', 'B': '2', 'C': '2'}]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qsne4xm4YTi-"
      },
      "source": [
        "# Task 2 - Tabulate the optimal policy & optimal value for each state in each round for N=10\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                                                    \n",
        "                                                                               "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW-PmCsHzeoa",
        "outputId": "aff4ce01-b086-4c59-b18d-9371f54e4ee0"
      },
      "source": [
        "import pandas as pd\n",
        "Rewards = Results[\"Expected Reward\"]\n",
        "Policies = Results[\"Polcies\"]\n",
        "print(\"Optimal Value for each state in each round\")\n",
        "rew = pd.DataFrame(Rewards, index = [i for i in range(9,-1,-1)])\n",
        "print(\"\\n\")\n",
        "print(rew)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Optimal Policy for each state in each round\")\n",
        "pol = pd.DataFrame(Policies, index = [i for i in range(9,-1,-1)])\n",
        "print(\"\\n\")\n",
        "print(pol)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimal Value for each state in each round\n",
            "\n",
            "\n",
            "            A           B           C\n",
            "9    8.000000   16.000000    7.000000\n",
            "8   17.750000   29.937500   17.875000\n",
            "7   29.664062   43.421875   30.906250\n",
            "6   42.965332   56.779785   44.137695\n",
            "5   56.295990   70.126251   57.472717\n",
            "4   69.639322   83.471014   70.815777\n",
            "3   82.983676   96.815581   84.160148\n",
            "2   96.328193  110.160122   97.504664\n",
            "1  109.672728  123.504661  110.849199\n",
            "0  123.017266  136.849198  124.193736\n",
            "\n",
            "\n",
            "Optimal Policy for each state in each round\n",
            "\n",
            "\n",
            "   A  B  C\n",
            "9  1  1  1\n",
            "8  1  2  2\n",
            "7  2  2  2\n",
            "6  2  2  2\n",
            "5  2  2  2\n",
            "4  2  2  2\n",
            "3  2  2  2\n",
            "2  2  2  2\n",
            "1  2  2  2\n",
            "0  2  2  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKsA1jrCKszh"
      },
      "source": [
        "# Question -  Consider a policy that always forces the driver to go to the nearest taxi stand, irrespective of the state. Is it optimal? Justify your answer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl502NaJHaPE"
      },
      "source": [
        "A policy that always forces the driver to go the nearest taxi stand (i.e. action 2 always) is an open loop policy. Closed loop policies are always better than open loop policies as in this case except when the policies are same. This is because a closed loop policy utlises the information until the stage k where we choose the action u(k), whereas in open loop policy we are forced to choose the policy at stage 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiAS3hQPkiXS"
      },
      "source": [
        "# Submit to AIcrowd üöÄ\n",
        "\n",
        "**NOTE: PLEASE SAVE THE NOTEBOOK BEFORE SUBMITTING IT (Ctrl + S)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfpXzdeTvjJ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7f9688d-4c30-4a9f-b21a-be6d5fac3149"
      },
      "source": [
        "!DATASET_PATH=$AICROWD_DATASET_PATH aicrowd notebook submit -c rl-taxi -a assets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using notebook: /content/Copy%20of%20IITM_RL_DP_ASSIGNMENT_v1 for submission...\n",
            "Removing existing files from submission directory...\n",
            "Scrubbing API keys from the notebook...\n",
            "Collecting notebook...\n",
            "Validating the submission...\n",
            "Executing install.ipynb...\n",
            "[NbConvertApp] Converting notebook /content/submission/install.ipynb to notebook\n",
            "[NbConvertApp] Executing notebook with kernel: python3\n",
            "[NbConvertApp] Writing 1694 bytes to /content/submission/install.nbconvert.ipynb\n",
            "Executing predict.ipynb...\n",
            "[NbConvertApp] Converting notebook /content/submission/predict.ipynb to notebook\n",
            "[NbConvertApp] Executing notebook with kernel: python3\n",
            "[NbConvertApp] ERROR | unhandled iopub msg: colab_request\n",
            "[NbConvertApp] ERROR | unhandled iopub msg: colab_request\n",
            "[NbConvertApp] ERROR | unhandled iopub msg: colab_request\n",
            "[NbConvertApp] ERROR | unhandled iopub msg: colab_request\n",
            "[NbConvertApp] ERROR | unhandled iopub msg: colab_request\n",
            "[NbConvertApp] ERROR | unhandled iopub msg: colab_request\n",
            "[NbConvertApp] ERROR | unhandled iopub msg: colab_request\n",
            "[NbConvertApp] ERROR | unhandled iopub msg: colab_request\n",
            "[NbConvertApp] ERROR | unhandled iopub msg: colab_request\n",
            "[NbConvertApp] Writing 25203 bytes to /content/submission/predict.nbconvert.ipynb\n",
            "\u001b[2K\u001b[1;34msubmission.zip\u001b[0m \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[35m100.0%\u001b[0m ‚Ä¢ \u001b[32m24.8/23.1 KB\u001b[0m ‚Ä¢ \u001b[31m1.9 MB/s\u001b[0m ‚Ä¢ \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h                                   ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ                                    \n",
            "                                   ‚îÇ \u001b[1mSuccessfully submitted!\u001b[0m ‚îÇ                                    \n",
            "                                   ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ                                    \n",
            "\u001b[3m                                         Important links                                          \u001b[0m\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ  This submission ‚îÇ https://www.aicrowd.com/challenges/rliitm-1/submissions/126638              ‚îÇ\n",
            "‚îÇ                  ‚îÇ                                                                             ‚îÇ\n",
            "‚îÇ  All submissions ‚îÇ https://www.aicrowd.com/challenges/rliitm-1/submissions?my_submissions=true ‚îÇ\n",
            "‚îÇ                  ‚îÇ                                                                             ‚îÇ\n",
            "‚îÇ      Leaderboard ‚îÇ https://www.aicrowd.com/challenges/rliitm-1/leaderboards                    ‚îÇ\n",
            "‚îÇ                  ‚îÇ                                                                             ‚îÇ\n",
            "‚îÇ Discussion forum ‚îÇ https://discourse.aicrowd.com/c/rliitm-1                                    ‚îÇ\n",
            "‚îÇ                  ‚îÇ                                                                             ‚îÇ\n",
            "‚îÇ   Challenge page ‚îÇ https://www.aicrowd.com/challenges/rliitm-1                                 ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfwpjWPr3yMm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
