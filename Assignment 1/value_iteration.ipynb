{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit ('base': conda)",
      "metadata": {
        "interpreter": {
          "hash": "ff00dac108179d3c1c82d8e6cb9ecf4e9dc3d3f409cd941b5c5be41e7679c1ce"
        }
      }
    },
    "colab": {
      "name": "Copy of IITM_RL_VI_v1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMOtbrHSzC1r"
      },
      "source": [
        "<div style=\"text-align: center\">\n",
        "  <a href=\"https://www.aicrowd.com/challenges/rl-vi\"><img alt=\"AIcrowd\" src=\"https://images.aicrowd.com/raw_images/challenges/banner_file/754/3fc6598e270b9219e215.jpg\"></a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXuhHGatRVNf"
      },
      "source": [
        "# What is the notebook about?\n",
        "\n",
        "## Problem - Value Iteration\n",
        "This problem deals with a grid world and stochastic actions. The tasks you have to do are:\n",
        "- Complete the Environment\n",
        "- Write code for value Iteration\n",
        "- Visualize Results\n",
        "- Explain the results\n",
        "\n",
        "## How to use this notebook? 📝\n",
        "\n",
        "- This is a shared template and any edits you make here will not be saved.**You\n",
        "should make a copy in your own drive**. Click the \"File\" menu (top-left), then \"Save a Copy in Drive\". You will be working in your copy however you like.\n",
        "\n",
        "- **Update the config parameters**. You can define the common variables here\n",
        "\n",
        "Variable | Description\n",
        "--- | ---\n",
        "`AICROWD_DATASET_PATH` | Path to the file containing test data. This should be an absolute path.\n",
        "`AICROWD_RESULTS_DIR` | Path to write the output to.\n",
        "`AICROWD_ASSETS_DIR` | In case your notebook needs additional files (like model weights, etc.,), you can add them to a directory and specify the path to the directory here (please specify relative path). The contents of this directory will be sent to AIcrowd for evaluation.\n",
        "`AICROWD_API_KEY` | In order to submit your code to AIcrowd, you need to provide your account's API key. This key is available at https://www.aicrowd.com/participants/me\n",
        "\n",
        "- **Installing packages**. Please use the [Install packages 🗃](#install-packages-) section to install the packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gzlHU3wRQRj"
      },
      "source": [
        "# Setup AIcrowd Utilities 🛠\n",
        "\n",
        "We use this to bundle the files for submission and create a submission on AIcrowd. Do not edit this block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMKvhbEKiFH5",
        "outputId": "412806c1-f281-4411-f8ed-a143c6b6c953"
      },
      "source": [
        "!pip install -U git+https://gitlab.aicrowd.com/aicrowd/aicrowd-cli.git@notebook-submission-v2 > /dev/null "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Running command git clone -q https://gitlab.aicrowd.com/aicrowd/aicrowd-cli.git /tmp/pip-req-build-cao1mtee\n",
            "  Running command git checkout -b notebook-submission-v2 --track origin/notebook-submission-v2\n",
            "  Switched to a new branch 'notebook-submission-v2'\n",
            "  Branch 'notebook-submission-v2' set up to track remote branch 'notebook-submission-v2' from 'origin'.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJuQ_nzaRpp6"
      },
      "source": [
        "# AIcrowd Runtime Configuration 🧷\n",
        "\n",
        "Define configuration parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBKm1IuliJc7"
      },
      "source": [
        "import os\n",
        "\n",
        "AICROWD_DATASET_PATH = os.getenv(\"DATASET_PATH\", os.getcwd()+\"/9db39385-0a4b-47db-8d20-fffb0480e47e_hw2_q2.zip\")\n",
        "AICROWD_RESULTS_DIR = os.getenv(\"OUTPUTS_DIR\", \"results\")\n",
        "API_KEY = \"a98ef81b017008edad014f38a0bb30ae\" # Get your key from https://www.aicrowd.com/participants/me (ctrl + click the link)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQnfZ7VYidPC",
        "outputId": "14e7838f-8535-4b09-d184-5a088b725719"
      },
      "source": [
        "!aicrowd login --api-key $API_KEY\n",
        "!aicrowd dataset download -c rl-vi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mAPI Key valid\u001b[0m\n",
            "\u001b[32mSaved API Key successfully!\u001b[0m\n",
            "9db39385-0a4b-47db-8d20-fffb0480e47e_hw2_q2.zip: 100% 3.08k/3.08k [00:00<00:00, 88.3kB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHqevxIX_4fo",
        "outputId": "8dac2ce2-1e77-4b51-de43-fab218155f4b"
      },
      "source": [
        "!unzip $AICROWD_DATASET_PATH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/9db39385-0a4b-47db-8d20-fffb0480e47e_hw2_q2.zip\n",
            "   creating: hw2_q2/\n",
            "   creating: hw2_q2/targets/\n",
            "  inflating: hw2_q2/targets/targets_0.npy  \n",
            "   creating: hw2_q2/sample_results/\n",
            "  inflating: hw2_q2/sample_results/sample_results_0.npy  \n",
            "   creating: hw2_q2/inputs/\n",
            "  inflating: hw2_q2/inputs/env_params_0.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm46inU6ABu-"
      },
      "source": [
        "DATASET_DIR = 'hw2_q2/'\n",
        "!mkdir {DATASET_DIR}results/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTeWFlWukTob"
      },
      "source": [
        "# Install packages 🗃\n",
        "\n",
        "Please add all package installations in this section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cusnfjYFRVNm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxdOqsVGRXKg"
      },
      "source": [
        "# Import packages 💻"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmhJUSs2Rjvh"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "import os\n",
        "from copy import deepcopy\n",
        "# ADD ANY IMPORTS YOU WANT HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP-1yA7URVNn"
      },
      "source": [
        "# Task 0 - Complete the environment\n",
        "You need to complete part of the environment which calculates the possible next states, their probabilities, and the reward."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GumM6eyWRVNn"
      },
      "source": [
        "class GridEnv_HW2:\n",
        "    def __init__(self, \n",
        "                 goal_location, \n",
        "                 action_stochasticity,\n",
        "                 non_terminal_reward,\n",
        "                 terminal_reward,\n",
        "                 grey_in,\n",
        "                 brown_in,\n",
        "                 grey_out,\n",
        "                 brown_out\n",
        "                ):\n",
        "\n",
        "        # Do not edit this section \n",
        "        self.action_stochasticity = action_stochasticity\n",
        "        self.non_terminal_reward = non_terminal_reward\n",
        "        self.terminal_reward = terminal_reward\n",
        "        self.grid_size = [10, 10]\n",
        "\n",
        "        # Index of the actions \n",
        "        self.actions = {'N': (-1, 0), \n",
        "                        'E': (0,1), \n",
        "                        'S': (1,0), \n",
        "                        'W': (0,-1)}\n",
        "        \n",
        "        # Do not worry about the names not matching the direction you expect\n",
        "        # Think of them as generic names and use the mapping to get the action direction and stochasticity\n",
        "        self.perpendicular_order = ['N', 'E', 'S', 'W']\n",
        "        \n",
        "        l = ['normal' for _ in range(self.grid_size[0]) ]\n",
        "        self.grid = np.array([l for _ in range(self.grid_size[1]) ], dtype=object)\n",
        "\n",
        "        self.grid[goal_location[0], goal_location[1]] = 'goal'\n",
        "        self.goal_location = goal_location\n",
        "\n",
        "        for gi in grey_in:\n",
        "            self.grid[gi[0],gi[1]] = 'grey_in'\n",
        "        for bi in brown_in:    \n",
        "            self.grid[bi[0], bi[1]] = 'brown_in'\n",
        "\n",
        "        self.grey_out = go = grey_out\n",
        "        self.brown_out = bo = brown_out\n",
        "\n",
        "        self.grid[go[0], go[1]] = 'grey_out'\n",
        "        self.grid[bo[0], bo[1]] = 'brown_out'\n",
        "        \n",
        "        self.states_sanity_check()\n",
        "    \n",
        "    def states_sanity_check(self):\n",
        "        \"\"\" Implement to prevent cases where the goal gets overwritten etc \"\"\"\n",
        "        pass\n",
        "\n",
        "    def visualize_grid(self):\n",
        "        pass\n",
        "\n",
        "    def _out_of_grid(self, state):\n",
        "        if state[0] < 0 or state[1] < 0:\n",
        "            return True\n",
        "        elif state[0] > self.grid_size[0] - 1:\n",
        "            return True\n",
        "        elif state[1] > self.grid_size[1] - 1:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def _grid_state(self, state):\n",
        "        return self.grid[state[0], state[1]]        \n",
        "        \n",
        "    def get_transition_probabilites_and_reward(self, state, action):\n",
        "        \"\"\" \n",
        "        Returns the probabiltity of all possible transitions for the given action in the form:\n",
        "        A list of tuples of (next_state, probability, reward)\n",
        "        Note that based on number of state and action there can be many different next states\n",
        "        Unless the state is All the probabilities of next states should add up to 1\n",
        "        \"\"\"\n",
        "\n",
        "        grid_state = self._grid_state(state)\n",
        "        \n",
        "        if grid_state == 'goal':\n",
        "            return [(self.goal_location, 1.0, 0.0)]\n",
        "        elif grid_state == 'grey_in':\n",
        "            return [(self.grey_out, 1.0, self.non_terminal_reward)]\n",
        "        elif grid_state == 'brown_in':\n",
        "            return [(self.brown_out, 1.0, self.non_terminal_reward)]\n",
        "        \n",
        "        direction = self.actions.get(action, None)\n",
        "        if direction is None:\n",
        "            raise ValueError(\"Invalid action %s , please select among\" % action, list(self.actions.keys()))\n",
        "\n",
        "        nextstates_prob_rews = []\n",
        "\n",
        "        # TASK 0 - Complete the environment\n",
        "\n",
        "        # ADD YOUR CODE BELOW - DO NOT EDIT ABOVE THIS LINE\n",
        "\n",
        "        if grid_state == 'normal' or 'grey_out' or 'brown_out':\n",
        "            self.action_stochasticity = list(self.action_stochasticity)\n",
        "            i = self.perpendicular_order.index(action)\n",
        "            action_probab = deepcopy( self.action_stochasticity[len(self.action_stochasticity)-i:] + self.action_stochasticity[:len(self.action_stochasticity)-i] )\n",
        "            for j in range(len(action_probab)):\n",
        "              if action_probab[j] != 0:\n",
        "                  nextstate = deepcopy((state[0] + self.actions[self.perpendicular_order[j]][0], state[1] + self.actions[self.perpendicular_order[j]][1]))\n",
        "                  if nextstate == (self.goal_location[0] , self.goal_location[1]):\n",
        "                    nextstates_prob_rews.append(deepcopy((nextstate , action_probab[j] , self.terminal_reward)))\n",
        "                  elif self._out_of_grid(nextstate):\n",
        "                    nextstate = deepcopy((state[0],state[1]))\n",
        "                    nextstates_prob_rews.append(deepcopy((nextstate , action_probab[j] , self.non_terminal_reward)))\n",
        "                  else:\n",
        "                    nextstates_prob_rews.append(deepcopy((nextstate , action_probab[j] , self.non_terminal_reward)))\n",
        "\n",
        "\n",
        "        # Hints: \n",
        "            # Get access to all actions with self.actions\n",
        "            # Use self.action_stochasticity for the probabilities of the other action\n",
        "                # The array will have probabilities for [0, 90, 180, -90] degrees\n",
        "                # So self.action_stochasticity = [0.8, 0.1, 0.0, 0.1] means 0.8 for forward and 0.1 for left and right\n",
        "            # Remember that you need to return a list of tuples with the form (next_state, probability, reward)\n",
        "            # If you have 3 possible next states, you should return [(ns1, p1, r1), (ns2, p2, r2), (ns3, p3, r3)]\n",
        "            # Use the helper function self._out_of_grid to check if any state is outside the grid\n",
        "            \n",
        "        # Important Note:\n",
        "            # Do not hard code any state locations, they may be changed in the submissions\n",
        "\n",
        "\n",
        "        # DO NOT EDIT BELOW THIS LINE\n",
        "\n",
        "        return nextstates_prob_rews"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVL7B0cjSZyy"
      },
      "source": [
        "# Question - When do you decide to stop value iteration \n",
        "\n",
        "**Answer **- \n",
        "\n",
        "Theoretically, value iteration stops at infinite iteration.\n",
        "But, Practically we can't allow the loop to run ot infinity. So, we assume convergence (i.e. Value Iteration has found the optimal cost and policy) has occured and stop the iteration when the maximum difference in value_grids' successive final iterations is below a tolerance value.(i.e. 1e-8 here)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD3Jgj2JRVNp"
      },
      "source": [
        "# Task 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIDOS51MWPU9"
      },
      "source": [
        "## a) Implement Value iteration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "45p2j33NRVNp"
      },
      "source": [
        "def value_iter(env):\n",
        "  value_grid = np.zeros((10, 10)) # Marked as J(s) in the homework pdf\n",
        "  policy = np.zeros((10, 10), np.int32) # Marked as pi(s) in homework pdf\n",
        "\n",
        "  value_grids = [] # Store all the J(s) grids at every iteration in this list\n",
        "  policies = []  # Store all the pi(s) grids at every iteration in this list\n",
        "\n",
        "  # ADD YOUR CODE BELOW - DO NOT EDIT ABOVE THIS LINE\n",
        "\n",
        "  l = -1\n",
        "  value_grid1 = np.zeros((10,10))\n",
        "  policy_grid1 = np.zeros((10, 10), np.int32)\n",
        "  while(True):\n",
        "    l = l+1\n",
        "    for i in range(10):\n",
        "      for j in range(10):\n",
        "            value = np.NINF\n",
        "            policy1 = ''\n",
        "            for actions in env.perpendicular_order :\n",
        "                nspr = env.get_transition_probabilites_and_reward((i,j), actions)\n",
        "                prob = deepcopy([ nspr[k][1] for k in range(len(nspr))])\n",
        "                ns = deepcopy([(nspr[k][0][0],nspr[k][0][1]) for k in range(len(nspr))])\n",
        "                rew = deepcopy([nspr[k][2] for k in range(len(nspr))])\n",
        "                value_grid1[i][j] =  sum( [ prob[k]*(rew[k] + value_grid[ns[k][0]][ns[k][1]]) for k in range(len(nspr))])\n",
        "\n",
        "                if value != value_grid1[i][j]:\n",
        "                  value = deepcopy(max(value_grid1[i][j], value))\n",
        "                  if value == value_grid1[i][j]:\n",
        "                    policy1 = deepcopy(actions)\n",
        "\n",
        "            value_grid[i][j] = deepcopy(value)\n",
        "            policy[i][j] = deepcopy(env.perpendicular_order.index(policy1))\n",
        "        \n",
        "\n",
        "    value_grids.append(deepcopy(value_grid))\n",
        "    policies.append(deepcopy(policy))\n",
        "\n",
        "\n",
        "    if l>=1:\n",
        "      converge = deepcopy(np.amax(np.absolute(value_grids[l]-value_grids[l-1])))\n",
        "      if converge < 1e-8:\n",
        "          #print(l)\n",
        "          #print(value_grids[l])           #Uncomment these lines to print the output\n",
        "          #print(policies[l])\n",
        "          break\n",
        "\n",
        "\n",
        "  # Important Note: \n",
        "  # The action names are strings but the expected output is an integer array\n",
        "  # To get the corresponding mapping of integer values use -> env.perpendicular_order\n",
        "  # So if your action is 'E' \n",
        "  # Your result would be: env.perpendicular_order.index('E') -> 1\n",
        "  \n",
        "\n",
        "  # DO NOT EDIT BELOW THIS LINE\n",
        "  results = {\"value_grid\": value_grid, \"pi_s\": policy}\n",
        "  return results, value_grids, policies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mus58g6PCx0I"
      },
      "source": [
        "## Here is an example of what the \"results\" output from value_iter function should look like\n",
        "\n",
        "**The numpy array may look different from the image given in the pdf because the origins are different, do not worry about this, use indexing and directions as providided by the env class (env.actions) and do not hard code anything.**\n",
        "\n",
        "Ofcourse, it won't be all zeros\n",
        "\n",
        "``` python \n",
        "{'value_grid': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
        "  'pi_s': array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLF4WYcrAx1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd75acf9-f9e2-4c80-b680-f0246b88ce31"
      },
      "source": [
        "# DO NOT EDIT THIS CELL, DURING EVALUATION THE DATASET DIR WILL CHANGE\n",
        "!mkdir $AICROWD_RESULTS_DIR\n",
        "input_dir = os.path.join(DATASET_DIR, 'inputs')\n",
        "for params_file in os.listdir(input_dir):\n",
        "  kwargs = np.load(os.path.join(input_dir, params_file), allow_pickle=True).item()\n",
        "  env = GridEnv_HW2(**kwargs)\n",
        "  results, value_grids, policies = value_iter(env)\n",
        "  idx = params_file.split('_')[-1][:-4]\n",
        "  np.save(os.path.join(AICROWD_RESULTS_DIR, 'results_' + idx), results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘results’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8IVf3N9VuNZ"
      },
      "source": [
        "#Task 2 - The value iteration loop goes to infinity (refer the pseudocode given above), so when would you stop your value iteration?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahKp_WLoYFN_"
      },
      "source": [
        "Practically we can't allow the loop to run ot infinity. So, we assume convergence (i.e. Value Iteration has found the optimal cost and policy) has occured and stop the iteration when the maximum difference in value_grids' successive final iterations is below a tolerance value.(i.e. 1e-8 here) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2r-zLDhRVNp"
      },
      "source": [
        "# Task 3- Plot graph of $||J_{i+1}(s) - J_i(s)||$\n",
        "An example plot code is provided below, but you can change it if you want"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFXPt6m6RVNq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "6312d895-ffb9-4200-e7d4-e21842f1c398"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "diffs = []\n",
        "for ii in range(len(value_grids)-1):\n",
        "    diff = np.linalg.norm(value_grids[ii+1] - value_grids[ii]) \n",
        "    diffs.append(diff)\n",
        "plt.plot(diffs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb6843514d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsEaK9L4RoZd"
      },
      "source": [
        "# Task 4 - Show $J(s)$ and $pi(s)$ after 10, 25 and final iteration. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0jPnRLvR-DF"
      },
      "source": [
        "# Use any visualization code you want to show the value and policies\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaE7G1FOSLhD"
      },
      "source": [
        "# Task 5 - Consider a new gridworld (GridWorld-2) as shown Figure 2 (GridWorld-2 differ from GridWorld-1 only in the position of the “Goal” state). Compare and contrast the behavior of J and greedy policy π for GridWorld-1 and GridWorld-2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cyik1NmZYC5s"
      },
      "source": [
        "Gridworld-1 has goal position at (9,9) and Gridworld-2 has goal position at (0,3). \n",
        "\n",
        "The trend of the rewards value around the goal location would be similar in both the cases. The optimal J would be zero at goal_location in both the cases and it will be close to the value of terminal_reward around it and it decreases slowly as we spread across the states. \n",
        "\n",
        "When greedy policy is concerned, the optimal policies for both the gridworlds are drastically different owing to the position of the goal location in both the cases. Changing the goal location alone can impact the optimal action taken in states around it and hence we find such a difference in the optimal policy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pNWylwjjCT1"
      },
      "source": [
        "# Submit to AIcrowd 🚀"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcCElHZnjDbI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fc5df19-3532-48cf-f7a1-f46694b862cb"
      },
      "source": [
        "!DATASET_PATH=$AICROWD_DATASET_PATH aicrowd notebook submit -c rl-vi -a assets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using notebook: /content/Copy%20of%20IITM_RL_VI_v1.ipynb for submission...\n",
            "Removing existing files from submission directory...\n",
            "Scrubbing API keys from the notebook...\n",
            "Collecting notebook...\n",
            "Validating the submission...\n",
            "Executing install.ipynb...\n",
            "[NbConvertApp] Converting notebook /content/submission/install.ipynb to notebook\n",
            "[NbConvertApp] Executing notebook with kernel: python3\n",
            "[NbConvertApp] Writing 1724 bytes to /content/submission/install.nbconvert.ipynb\n",
            "Executing predict.ipynb...\n",
            "[NbConvertApp] Converting notebook /content/submission/predict.ipynb to notebook\n",
            "[NbConvertApp] Executing notebook with kernel: python3\n",
            "[NbConvertApp] ERROR | unhandled iopub msg: colab_request\n",
            "[NbConvertApp] ERROR | unhandled iopub msg: colab_request\n",
            "[NbConvertApp] ERROR | unhandled iopub msg: colab_request\n",
            "[NbConvertApp] ERROR | unhandled iopub msg: colab_request\n",
            "[NbConvertApp] ERROR | unhandled iopub msg: colab_request\n",
            "[NbConvertApp] ERROR | unhandled iopub msg: colab_request\n",
            "[NbConvertApp] ERROR | unhandled iopub msg: colab_request\n",
            "[NbConvertApp] ERROR | unhandled iopub msg: colab_request\n",
            "[NbConvertApp] ERROR | unhandled iopub msg: colab_request\n",
            "[NbConvertApp] ERROR | unhandled iopub msg: colab_request\n",
            "[NbConvertApp] ERROR | unhandled iopub msg: colab_request\n",
            "[NbConvertApp] ERROR | unhandled iopub msg: colab_request\n",
            "[NbConvertApp] Writing 40363 bytes to /content/submission/predict.nbconvert.ipynb\n",
            "\u001b[2K\u001b[1;34msubmission.zip\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.0%\u001b[0m • \u001b[32m60.0/58.3 KB\u001b[0m • \u001b[31m339.9 kB/s\u001b[0m • \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h                                   ╭─────────────────────────╮                                    \n",
            "                                   │ \u001b[1mSuccessfully submitted!\u001b[0m │                                    \n",
            "                                   ╰─────────────────────────╯                                    \n",
            "\u001b[3m                                         Important links                                          \u001b[0m\n",
            "┌──────────────────┬─────────────────────────────────────────────────────────────────────────────┐\n",
            "│  This submission │ https://www.aicrowd.com/challenges/rliitm-1/submissions/126693              │\n",
            "│                  │                                                                             │\n",
            "│  All submissions │ https://www.aicrowd.com/challenges/rliitm-1/submissions?my_submissions=true │\n",
            "│                  │                                                                             │\n",
            "│      Leaderboard │ https://www.aicrowd.com/challenges/rliitm-1/leaderboards                    │\n",
            "│                  │                                                                             │\n",
            "│ Discussion forum │ https://discourse.aicrowd.com/c/rliitm-1                                    │\n",
            "│                  │                                                                             │\n",
            "│   Challenge page │ https://www.aicrowd.com/challenges/rliitm-1                                 │\n",
            "└──────────────────┴─────────────────────────────────────────────────────────────────────────────┘\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQIQi6-bMH8Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
